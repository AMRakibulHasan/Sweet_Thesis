\chapter{Introduction}

Cyber Alert data is complex due to intricate feature dependencies, lack of homogeneity and stationarity, and rarity of malignant samples. In order to further understand these characteristics of alert data it is important to understand how it is collected, each specific challenge presented by the data, and how potential methods of synthetic generation need to account for these challenges. 

\section{Network Intrusion Detection Systems}
A variety of packet capture tools exist to enable individuals and corporations alike to monitor traffic on their networks. Several tools take this logging a step further and allow for real time network intrusion detection. Network Intrusion Detection Systems (NIDS) are a rule based system which allows for automated flagging of potentially malignant packet traffic through the aggregation of temporally contiguous packets;  these alerts typically consist of the believed attack signature, a category that the attack falls under, target machine, timestamp, and more. These systems are employed to flag potentially malicious traffic, note long term patterns in traffic, and provide system administration with a trail of alerts to analyze after a cyber-attack has taken place. 

Though these tools provide network operators with a wealth of data to analyze they suffer from a fundamental issue. The data only exists after a cyber attack has already taken place, and therefore only allows for reactionary defense techniques. This has lead researchers to see if they can use this data, as well as simulations and extrapolation, to further understand network vulnerabilities in the pursuit of proactive cyber security. 

\section{Challenges of Cyber Alert Data}
Cyber Alert data suffers from two primary challenges; There is a lack of malicious traffic data and the data that does exist is imbalanced, non-homogeneous, and unlabeled. 

Access to malicious NIDS alert data has been a long standing problem for researchers in the domain of Cyber Security. As an alternative probablistic models, such as attack graphs \cite{Qin2004, Wang2006, Noel2009}, have been proposed and updated to try and create realistic attack data for varying network architectures in an automated fashion. These models provide insight into potential attack paths within a network, the probability a given path will be used, and what vulnerabilities within the network allow for these paths to exist. Other works have defined methods to model these attack graphs as Markov Chains \cite{Li2017}, while others have employed statistical graph models \cite{Du2014} and Variable Length Markov Models \cite{Fava2008} in attempts to better understand potential vulnerabilities. Despite the effectiveness of these models however they lack any means to consider historical attack data or consider real network alerts. 

Of the datasets which do exist, common issues include small data set size, high imbalance between malignant and benign alerts, redundant samples, and intricate interactions leading to misleading labels. One example of this is the KDD Cup '99 \cite{kdd-cup} dataset. This dataset was prepared by Stolfo \etal \cite{Stolfo} based off data captured in DARPA'98 IDS evaluation program \cite{Lippmann}. It consists of samples from 7 weeks of network traffic collected via TCPdump that was labeled with one of 5 labels {normal, denial of service, user to root attack, remote to local attack, or probing attack}. Recently, it been used for multiple studies involving cyber attack classification and prediction through the use of recurrent neural networks (RNNs) \cite{Kim, Staudemeyer}. However this dataset contains several pathological issues such as synthetic background traffic, underlying issues with TCPdump under intense load, and a lack of precise definitions for what constitutes an attack, as highlighted by Tavallaee \etal \cite{Tavallaee} and McHugh \cite{McHugh}.

Other publicly available datasets struggle with a low signal to noise ratio. Two examples of this are the Multi Source Cyber Event Dataset published by Los Alamos National Laboratory \cite{akent-2015-enterprise-data} and the DeepSecurity Dataset released by Faber and Malloy \cite{Faber2018}. The Multi Source Cyber Event Dataset contains 4.8 KB of textual information pertaining to malicious events. The magnitude of these events pales in comparison to the overall scale of the dataset, which is encompassed in 12.2 GB of textual data. DeepSecurity faces a similar issue with a low percentage of their 600,000 network events being representative of malicious network traffic. The authors note that the availability of quality labeled data and a low signal to noise ratio for malicious activity are both outstanding issues with their studies \cite{Faber2018}. 

Though the distribution of malicious events in these datasets may be representative of real world cyber alert data it creates many challenges for network defense. These challenges include the potential obfuscation of attack behavior, difficulty isolating malicious alerts interspersed throughout a stream of non-malicious alerts, and no ground truth labels. With no commonly accepted means to artificially generate additional malicious alert data, these challenges persist in the field of Cyber Security. 

\section{Generative Adversarial Networks}

A Generative Adversarial Network (GAN) is a class of neural network where two neural networks are pitted against each other. One network, the generator, attempts to create samples which seem to belong to a ground truth dataset. The other network, the discriminator, takes inputs from the ground truth dataset as well as the generator and flags samples as either real or fake. This structure minimizes the generator loss each time the generator successfully creates a sample that tricks the discriminator into marking the sample as real. Conversely, the discriminator loss is minimized when all samples from the ground truth set are marked as real and all samples created by the generator are marked as fake.

GANs have achieved state of the art results in generating data with respect to images \cite {Karras2018, Zhu2017, Ledig2016}, text \cite{Su2018}, and sound \cite{Dong2018, Gao2018}.  Additionally, they have also been shown to perform well at more complex tasks such as scene to scene translation in images \cite{Zhu2017, Choi2017} and stylized image generation \cite{Karras2018}. These architectures allow GANs to serve as a powerful tool to artificially expand datasets. Additionally, high fidelity data generation requires the generator to learn key dependencies between features within each generated sample. A means to reveal and analyze these dependencies would be a powerful tool for analyzing critical features within the dataset.

Despite these successes, GANs do have several shortcomings. They are noted for requiring large numbers of samples per class and are typically trained across very large datasets for many epochs. The loss functions do not represent the quality of the data, as both the generator and discriminator are continually learning; as one network becomes better it's loss may drop, only to rise back up in a few batches when the other network learns something new as well. This lack of convergence makes training and hyperparameter tuning even more important than in traditional Deep Learning models. Allowing one model to overpower the other starves the system from having any useful gradient feedback. Finally, output mode dropping may occur, as the generator may not receive sufficient gradient feedback to encourage full exploration of the dataset.

\section{Problem Statement}

In order to address the lack of malicious NIDS alert data for cyber attack studies we explore artificial cyber alert synthesis. Due to the intricate feature relationships, data imbalance, and stochastic nature of alerts we employ the use of GANs. The application of GANs is challenged by potential for output mode collapse and failure of the network to learn realistic output distributions for each feature. Generalized preprocessing techniques are defined to prepare NIDS alert data for usage with GANs while also making model inputs and outputs more intuitive for analysis. 

Since there is no commonly accepted metric to score the fidelity of synthetically generated alerts, several desirable attributes for alert fidelity scoring are defined. Subsequently, histogram intersection and Jensen Shannon divergence are proposed as metrics which meet these criteria and are used to evaluate synthetically generated alerts from a GAN. Advantages and disadvantages of each metric are reviewed. 

Furthermore, conditional entropy and joint entropy are suggested as means to measure the efficacy of the GAN on learning the intricate feature interactions within an alert. Conditional probability tables are also employed to further understand the degree to which GANs learn feature dependencies. These methods provide insight into the critical features of alert data even when applied outside the context of analyzing synthetically generated alerts. Additionally, they provide detailed contextual information by allowing researchers to directly analyze feature-value relationships in alert data. 

Finally, mutual information maximization is proposed as a means to regularize the generators output. This addition encourages further exploration of the ground truth dataset and reduces output mode collapse.  


