%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%TODO:
% * Fix Acknowledgments formatting
% * Clean up Abstract for flow
% * Simulation and Modeling Subsection?
% * TM marker on Suricata?
% *
% *
% *
% *
% *
% *
% *
% *
% *
% *
% *
% *
% *
% *
% *
% *
% *
% *
% *
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[12pt,american]{report}

\def\Reals{\mathbf{R}}
\def\Ints{\mathbf{Z}}
\def\Nats{\mathbf{N}}
\def\E{\mathbb{E}}
\def\Q{\mathbb{Q}}
\def\P{\mathbb{P}}
\def\A{{\cal A}}

\usepackage{.//sty//rit-coe-thesis}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%   The following packages are all optional and depend on the specifics of what
% is contained in the thesis.  There is no harm in leaving them in.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{subfigure}
\usepackage{babel}
\usepackage{times}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{lscape}
\usepackage{verbatim}
\usepackage{enumerate}
\usepackage{afterpage}
\usepackage{glossaries}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%   Mark the document as 'draft' with a date. Be sure to comment this out for
% the final version.
%\usepackage{watermark}
%\watermark{\hspace{-0.3in} \textbf{DRAFT} \hspace{2.0in} \textbf{\today}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% For graphics (do not remove)
  \DeclareGraphicsExtensions{.pdf,.pgf,.png}
  \graphicspath{{.//figs//}}

\makeglossaries

\newglossaryentry{rit}{name={RIT},description={Rochester Institute of Technology}}

\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Title page
% The \title{} can contain line breaks as appropriate...
\title{\vspace{-0.20in}Applying Generative Adversarial Networks to Cyber-Alert Data}
% The \titleline{} must have no line breaks in it.
\titleline{Applying Generative Adversarial Networks to Cyber-Alert Data}
% There should be no reason to change the \thesistype{} or the \MSThesistrue...
\thesistype{Thesis}
\MSthesistrue
% This date is really not used (unless \grantdate{}{} is blank)
% This date is really not used (unless \grantdate{}{} is blank)
\date{April 2019}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% AUTHOR
% The \author{} should be exactly the same as your diploma
    \author{Christopher R. Sweet}
    \dept{Computer Engineering}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% COMMITTEE MEMBERS
% The following information is for the signature page.
% Note that the definition for principal adviser uses two fields.
% This was needed so that the adviser's name could be placed on the
% abstract page without his/her title.
% \foursigstrue | \fivesigstrue but don't define BOTH to be true!!
    \principaladviser{Dr. Shanchieh Yang}{Professor}
    \advdept{Computer Engineering}
    \firstreader{Dr. Raymond Ptucha}{Assistant Professor}
    \firstdept{Computer Engineering }
    \secondreader{Dr. Sonia Lopez Alarcon}{Associate Professor}
    \seconddept{Computer Engineering}
    
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Use this only if \foursigstrue
%\thirdreader{Reader Three \\ Reader3 Title}
%\thirdreader
% Use this only if \fivesigstrue
%\fourthreader{Reader Four \\ Reader4 Title}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% This is the expected date that the committee will sign your thesis.
\grantdate{April}{2019}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% If you want to copyright your thesis / dissertation remove the line below.
\copyrightfalse% True by default
% The year of the copyright; usually same as the date the committee will
% sign the thesis. This won't be printed if \copyrightfalse
\copyrightyear{2019}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% This causes all front matter to be set.
\beforepreface%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% The dedication - if you choose to include one.
% It should be vertically centered in the page. Since the style format doesn't
% do it for you automatically, you can use the following technique.
\prefacesection{Dedication}
\vfill
\begin{center}
To my mother and father, Debbie and Jack Sweet, who taught me the value of a strong work ethic. And to my brother who always set an extremely high bar for me to try and beat.  Without your continued support and guidance I would never have been able to achieve all that I have. 
\end{center}
\vfill
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% The acknowledgements page - if you choose to include one.
% As in the dedication, it should be centered vertically in the page.
%
\prefacesection{Acknowledgments}
\vfill
\begin{center}
\indent Most importantly, thank you to Dr. S. Jay Yang for providing me with the opportunity to assist in research throughout my undergraduate study. Your continued feedback and encouragement to challenge myself over the years has helped me to grow into a strong engineer and critical thinker. You have had a profound impact on me, and I can never thank you enough for that. Next, I would like to thank Dr. Raymond Ptucha, Dr. Sonia Lopez-Alarcon, and the rest of the RIT Computer Engineering faculty for their willingness to educate the next generation of Computer Engineers. Finally, I would like to thank the soon to be Dr. Stephen Moskall who provided me my first opportunity to work with him and Dr. Yang when I was in my second year of undergrad. I cannot thank you enough for the professional and personal advice, as well as the good times in lab, that you have provided over the last four years.  
\end{center}
\vfill
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%  Collection of useful abbreviations.
\newcommand{\etc} {\emph{etc.\/}}
\newcommand{\etal}{\emph{et~al.\/}}
\newcommand{\eg}  {\emph{e.g.\/}}
\newcommand{\ie}  {\emph{i.e.\/}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Abstract
\begin{abstractpage}
	%1. High Level Problem Statement (Enterprise Networks and Challenges of Data)
	%2. Machine Learning (GAN and C-Sec Challenges)
	%3. This work...
	
Enterprise computer networks continue to grow in complexity and importance as reliance on network operation for day to day activities grows. Additionally, the number and severity of attacks perpetrated against these networks also continually grows. These attacks can disrupt business operation, influence markets, and even impact governmental actions. Methods for capturing malignant network behavior are often employed through network intrusion detection systems to allow for real time traffic analysis and anomaly detection. However, cyber-alert data lacks homogeneity, is inherently imbalanced, and is difficult to isolate and apply labels to. This poses a challenge to predictive models used for proactive Cyber Security. 

Generative Adversarial Networks (GAN) encompass a type of neural network architecture which learns to recreate data based off an existing dataset. GANs have now been applied to a variety of field, such as Computer Vision, Natural Language Processing, and Cyber Security for adversarial sample crafting. In Computer Vision and Natural Language Processing there are large publicly available datasets to use for training and testing machine learning models; in the field of Cyber Security few analogs exist. By turning towards data generative algorithms, smaller datasets with wide variability may be artificially expanded and used in further study/simulation. Additionally, feature dependencies may be revealed and analyzed allowing for direct application to improved network defense.

This work applies state of the art Generative Adversarial Networks to known malicious cyber alert data with the intent of achieving high fidelity data generation. Unique preprocessing steps, model considerations, and training methods are reviewed. Additionally, several methods for data fidelity evaluation are proposed; Including intersection of histograms for varying combinations of features, Jensen Shannon Divergence, and conditional and joint entropy calculations. Thorough examination of these metrics is shown to not only identify key aspects of the performance of GANs applied to Cyber Alert data, but also key relationships in the network traffic behavior. 

\end{abstractpage}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Uncomment the line below if you don't want a list of tables to be printed.
% \tablespagefalse

% Uncomment the line below if you don't want a list of figures to be printed.
% \figurespagefalse

% \afterpreface generates the table of contents, list of tables (optional),
% and list of figures (optional).
\afterpreface%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\printglossaries

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% This is where the main body of the thesis starts
\body%
\chapter{Introduction}

\section{Network Intrusion Detection Systems}
A variety of packet capture tools exist to enable individuals and corporations alike to monitor traffic on their networks. Several tools take this logging a step further and allow for real time network intrusion detection. Network intrusion detection systems (NIDS) are a rule based system which allows for automated flagging of potentially malignant packet traffic through the aggregation of temporally contiguous packets;  These "alerts" typically consist of the believed attack signature, a category that the attack falls under, target machine, timestamp, and more.   For example, the Suricata NIDS is capable of processing up to $30,000$ packets per second. This kind of high volume traffic may occur when an attack initiates a comprehensive network scan and may only result in a few alerts stating that there is scanning activity occuring. These systems are employed to flag potentially malicious traffic, note long term patterns in traffic, and provide system administration with a trail of alerts to analyze after a cyber-attack has taken place. 

Though these tools provide network operators with a wealth of data to analyze they suffer from a fundamental issue. The data only exists after a cyber attack has already taken place, and therefore only allows for reactionary defense techniques. This has lead researchers to see if they can use this data, as well as simulations and extrapolation, to further understand network vulnerabilities in the pursuit of proactive cyber security. 

\section{Challenges of Cyber Alert Data}
Cyber Alert data suffers from two primary challenges; There is a lack of publicly available data and the data that does exist is imbalanced, non-homogeneous, and unlabeled. 

The lack of publically available datasets has pushed researchers to develop probablistic models for attack path prediction. This is type of model is known as an attack graph and has taken on many implementations as seen in \cite{Qin2004, Wang2006, Noel2009}. All of the reviewed implementations attempt to map all possible attacks for a network given it's architecture in an automated way. These models can provide which attack path is most likely to be used by attackers, how many attack paths exist within the network, and what are key vulnerabilities in a network when mapped to a Markov Chain, as shown by Li \cite{Li2017}. Other works have attempted to identify patterns and obfuscation techniques through the use of Variable Length Markov Models \cite{Fava2008} and statistical graph models \cite{Du2014}


Of the datasets which do exist, common issues include small data set size, high imbalance between malignant and benign alerts, redundant samples, and intricate interactions leading to misleading labels. One example of this is the KDD Cup '99 \cite{kdd-cup} dataset. This dataset was prepared by Stolfo \etal \cite{Stolfo} based off data captured in DARPA'98 IDS evaluation program \cite{Lippmann}. It consists of samples from 7 weeks of network traffic collected via TCPdump that was labeled with one of 5 labels {normal, denial of service, user to root attack, remote to local attack, or probing attack}. Recently, it been used for multiple studies involving cyber attack classification and prediction through the use of recurrent neural networks (RNNs) \cite{Kim, Staudemeyer}. However this dataset contains several pathological issues such as synthetic background and attack data based off real world samples, underlying issues with TCPdump under intense load, and a lack of precise definitions for what constitutes an attack, as highlighted by Tavallaee \etal \cite{Tavallaee} and McHugh \cite{McHugh}.

Other publicly available datasets struggle with a low signal to noise ratio. Two examples of this are the Multi Source Cyber Event Dataset published by Los Alamos National Laboratory \cite{akent-2015-enterprise-data} and the DeepSecurity Dataset released by Faber and Malloy \cite{Faber2018}. For example, the Multi Source Cyber Event Dataset contains 4.8 KB of information in textual format pertaining to malicious events. The magnitude of these events pales in comparison to the overall scale of the dataset, which is encompassed in  12.2 GB of textual data. DeepSecurity faces a similar issue with a low percentage of their 600,000 network events being representative of malicious network traffic. The authors note that the availability of quality labeled data and a low signal to noise ratio for malicious activity are both outstanding issues with the data. 

Though the distribution of malicious events in these datasets may be representative of real world cyber alert data it creates many challenges for network defense. These challenges include the potential obfuscation of attack behavior, difficulty isolating malicious alerts interspersed throughout a stream of non-malicious alerts, and no ground truth labels. 

\section{Generative Adversarial Networks}

A Generative Adversarial Network (GAN) is a class of neural network where two neural networks are pitted against each other. One network, the generator (G), attempts to create samples which seem to belong to a ground truth dataset. The other network, the discriminator (D), takes inputs from the ground truth dataset as well as G, and flags samples as either real or fake. This structure minimizes the generator loss each time G successfully generates a sample that tricks D into marking the sample as real. Conversely, the discriminator loss is minimized when all samples from the ground truth set are marked as real and all samples created by G are marked as fake.

GANs have achieved state of the art results in generating data with respect to images \cite {Karras2018, Zhu2017, Ledig2016}, text \cite{Su2018}, and sound \cite{Dong2018, Gao2018}.  Additionally, they have been shown to also perform well at more complex tasks such as scene to scene translation in images \cite{Zhu2017, Choi2017} and stylized image generation \cite{Karras2018}. This allows GANs to serve as a powerful way to artificially expand datasets which may require more samples than originally collected. The potential application of GANs only continues to grow as researchers in new fields apply them to challenging sample generation tasks.

Despite these successes GANs have several shortcomings. They are noted as being 'data hungry' and are typically trained across very large datasets for many epochs. The loss functions do not represent the quality of the data, as both the generator and discriminator are continually learning; as one network becomes better it's loss may drop, only to rise back up in a few batches when the other network learns something new as well. This lack of convergence makes training and parameter tuning even more important than traditional Deep Learning models. Allowing one model to overpower the other starves the system from having any useful gradient feedback. Finally, output mode dropping may occur, as the generator may be penalized too severally as it tries to learn to generate samples which do not occur often. 

\section{Problem Statement}

Cyber event datasets typically lack homogeneity, are imbalanced, and are difficult to obtain and apply labels to. This poses a challenge to predictive models used for proactive Cyber Security. Generative Adversarial Networks encompass a type of neural network architecture which learns to recreate data based off the approximated PDF of an input training set. It is the goal of this research to explore the degree to which a GAN can emulate a dataset consisting of temporally linked cyber alerts. The fidelity of the generated data is challenged by GAN’s lack of convergence, potential for parameter setting collapse, and potential oversimplification of the features expressed in the sampled data. Further, the methods of identifying this fidelity is a non-trivial matter; no metric exists to indicate the fidelity of cyber event data. 

To identify the fidelity a GAN recreates cyber alerts with, methods evaluating said fidelity must be defined. One proposed metric is to use the intersection of histograms for each feature, and each possible combination of features, between the real and generated dataset. This metric has the benefit of being intuitive to visualize and analyze for low dimensional representations of the data. Additionally, the Jensen Shannon Divergence may also be used to compare alerts from the ground truth and generated set; this metric has the benefit of a nonlinear penalty for failing to capture the true probability of specific outputs. Each of these metrics have a rich history for comparing discrete feature histograms. Finally, Joint and Conditional Entropy between varying alert features are shown to be able to hightlight the difficulty of generating a given feature, as well as critical feature relationships in each distribution. These values also reinforce the power of GANs, as they may be used to show that these feature dependencies are indeed captured by the model and important to successfully generating features which would not occur often if considered in isolation. 

With each of the above proposed metrics there are unique insights and drawbacks. Histogram representation of the dataset allows the data to be analyzed wholelistically, but only after a cyber event has taken place. The scores provided by these metrics may also fail to account for the complexity of the dataset or fail to represent useful data. For example, the intersection of histograms between alert signatures would not be a full representation of cyber events, as alert signature alone does not provide enough contextual information to be useful. However, when coupled with other features, such as destination port or latent network information such as the target machine's purpose (e.g. HTTP Server) salient attack information may be inferred. This can lead to insights regarding the ability of the network to learn the behavior of the attackers, rather than replicate their actions identically. Comparing conditional entropy tables for the ground truth and generated dataset can help to identify critical relationships between features. That is to say, some feature values may only be learned by the generator because of their relationship to another feature's value.

\chapter{Related Work}

With the recent resurgence of Machine Learning, and newfound abilities of Deep Learning models, researchers across a variety of domains have begun to apply these methods to outstanding challenges in their fields. Cyber-Security has not evaded this, as Deep Neural Networks have been used for cyber event classification, forecasting, malicious traffic modification, and now data generation. This section shall be organized as follows: First, a survey of existing applications of Machine Learning to Cyber Security problems will be reviewed to illustrate the need for rich alert datasets. Then advances in generative models from other fields will be examined to better understand how state of the art generative models achieve the results that they do. And finally, the current use case of generative models for cyber security will be compared to the methods proposed by this work. 

\section{Cyber Security and Machine Learning}

The predominant application of Machine Learning to Cyber Security has been focused on the challenge of anomaly detection, attack classification, and event prediction. For all of these tasks intricate relationships must be considered between the various features of alerts as well as entire chains of temporally connected alerts. 

In order to maintain these temporal relationships Recurrent Neural Networks have been employed. Specifically, Long Short Term Memory (LSTM) units allow for the network to learn how to weight the importance of prior events and when to forgot alerts entirely. These models have been applied to Cyber Physical Systems by Filonov \etal to identify anomalous behavior. Their results demonstrate the power of LSTM for Cyber Security as they outperform traditional methods such as PCA, FDA, DFDA, CVA and SVM based anomaly detection \cite{Filonov2016, Filonov2017} on the Numenta Anomaly Benchmark \cite{Lavin2015}

Other works make use of the aforementioned KDD Cup'99 dataset for cyber event classification. Both the works of Staudemeyer \etal \cite{Staudemeyer} and Kim \etal \cite{Kim} show that LSTM networks are able to achieve impressive results near $100\%$ accuracy when tasked with identifying if a stream of traffic is normal, or falls into one of the four malignant labels. 

This type of problem is echoed by Tuor \etal \cite{Tuor} who use system logs and a twin neural network model to identify if traffic is malignant. The first model extracts information from the past $24$ hours of system logs by embedding a mixture of categorical and event count features into a hidden representation. A series of these hidden representations are then fed into the second model, an LSTM network, which classifies potential cases of malignant behavior. Through the usage of a fixed sliding window the dataset may be continuously updated. This allows for a continuous training approach to be used, keeping models up to date regarding new system log behavior. 

Another such example would be $AI^2$ \cite{Veeramachaneni2016} which integrates expert input into the network traffic used for training an LSTM. The LSTM learns identify anomalous behavior which is then classified by a human analyst. The analyst's feedback is then given to the network and used for future parameter updates so that future events may be flagged with a higher degree of accuracy.

Other works have taken the challenge of prediction and classification a step further and attempted to forecast attributes of future attacks. One example of this is the work of Perry \etal \cite{us} who applied LSTMs to a collegiate penetration testing competition to see if alerts early in the competition could be used to identify which team was perpetrating an attack later on in the event. Further, they also showed that attributes of future attacks could be forecast, such as the alert signature (what) and destination port (where). 

Similarly Shen \etal \cite{Shen2018} applied LSTMs to a dataset of 3.4 billion security events collected from Symantec's Intrusion Prevention Product deployed on corporate networks which have opted in to it's data sharing program. Their results demonstrate that LSTM can be used to predict target machine, attack severity, and even specific common vulnerability exploits which may be used in the attack with over $80\%$ accuracy. 

All of these systems for attack classification and prediction make use of data collected via NIDS. Despite the promising results of each, several of the authors note that they believe and increased dataset would allow for them to further improve the accuracy of their models \cite{us, Faber2018, Shen2018}. 

\section{Generative Adversarial Networks: Models and Improvements}

First proposed by Goodfellow \etal \cite{Goodfellow2014}, GANs are a game theoretic model for generating increasingly realistic data in a semi supervised manner. The generator learns a set of nonlinear transformations ($T$) to apply to noise $\widehat{x}$ sampled from $\P_{\widehat{x}}$. These transformations result in data which imitates that of the ground truth set $x$ sampled from $\P_r$. The discriminator is fed both real,  $x$ sampled from $\P_r$, and generated, $\widetilde{x}$ sampled from $\P_g$, data and assigns a probability $p \in [0,1]$ representing the believed probability that a sample came from the distribution $\P_r$. 

Immediately GANs proved themselves to be a powerful tool for the generation of new samples in continuous value spaces such as images. Rapid advances came through the application of Conditional generation \cite{Mirza2014}, Deep Convolutional Networks \cite{Radford2015}, and Information Theoretic extensions \cite{Chen2016}. 

Simultaneously the training and structure of GANs were updated to improve convergence rates, palliate output mode dropping, and provide meaningful learning curves \cite{Salimans, Arjovsky2017, Gulrajani2017}. Most notably, the Wasserstein GAN proposed by Arjovsky \etal \cite{Arjovsky2017} introduced the usage of the Earthmover Distance as the loss function for both the generator and discriminator. Intuitively, this distance represents how much "mass" must be transported from x to y in order to transform $\P_g$ into $\P_r$. 

WGAN was subsequently improved by Gulrajani \etal \cite{Gulrajani2017} by adding a gradient penalty term (WGAN-GP) to regularize the gradients of D. The gradient penalty creates a 1-Lipschitz constraint on the discriminator during training by sampling noise $\widehat{x}$ from $\P_{\widehat{x}}$ and constraining the gradient of the L2 norm of D to 1. Additionally, the discriminator was given real samples and generated samples in a 5:1 ratio per epoch of training; this is done to increase the utility of gradients provided to the generator by discriminator. These modifications to training result in the loss formulation shown in (\ref{eq:WGAN-GP1}), (\ref{eq:WGAN-GP2}), and (\ref{eq:WGAN-GP3}) for the discriminator, the gradient penalty term, and the generator respectively:

\begin{align}
	D_{loss} &=  \E_{\widetilde{x} \thicksim \P_g}[D(\widetilde{x})] - \E_{x \thicksim \P_r}[D(x)] + \label{eq:WGAN-GP1} \\
	& \lambda \E_{\widehat{x} \thicksim \P_{\widehat{x}}}[(||\nabla_{\widehat{x}} D(\widehat{x})||_2 -1)^2] \label{eq:WGAN-GP2}\\
	G_{loss} &=  -\E_{\widetilde{x} \thicksim \P_g}[D(\widetilde{x})] \label{eq:WGAN-GP3}
\end{align}

\begin{equation}
	D_{KL}(P||Q) = \sup\limits_{T:\Omega \rightarrow \Reals} \E_\P[T] - \log(\E_\Q[e^T])
	\label{eq:MINE}
\end{equation}

Separate from the advances of WGAN and WGAN-GP, Mutual Information Neural Estimation (MINE) \cite{Belghazi2018} was introduced as a means to help palliate output mode dropping and improve reconstruction of generative models. MINE uses a neural network optimized using the Donsker-Varadhan representation of the KL-Divergence, given in (\ref{eq:MINE}), to estimate the mutual information $I$ between two distributions. They then show that this architecture may be used with GANs by using the Mutual Information estimate to regularize the generator's loss by simply adding the term $I(G([z];z))$. The results of adding such a term was the complete removal of mode dropping in several benchmarks.

\section{Applications of Generative Adversarial Networks to Network Traffic: Adversarial Sample Crafting}

One common application of GANs has been the creation of Adversarial Samples. First noted by Szegedy \etal \cite{Szegedy2013}, Adversarial Samples are generated by taking ground truth samples, applying a small, human-imperceptible, perturbation, resulting in that sample being misclassified by a neural network with a high degree of confidence. Subsequent research found more powerful ways to generate Adversarial Samples through methods such as fast gradient sign \cite{Goodfellow2015}, optimization based methods \cite{Carlini2017, Liu2017, Eykholt2018}, and GANs \cite{Xiao2018}. 

Advarsarial Sample Crafting has been applied to network traffic to modify and obfuscate malicious traffic \cite{Rigaki2018, Lin2018, Hu2017, Anderson2017}. These adversarial samples are created to avoid being flagged by Network Intrusion Detection Systems (NIDS).

Rigaki \etal \cite{Rigaki2018} proposed the use of GANs in generating network traffic which mimics other types of network traffic. In particular, real malware traffic was modified by a GAN to appear as legitimate network traffic. This allowed the malware to avoid detection from the Stratosphere Behavioral Intrusion Prevention System through the modification of three network traffic parameters; total byte size, duration of network flow, and time delta between current network flow and the last network flow. They showed that through the modification of these parameters detection rate could be dropped down to 0\%. 

Similarly, Lin \etal \cite{Lin2018} apply GANs to obfuscate traffic with the intention of directly deceiving a NIDS. Their model makes use of 9 discrete features and 32 continuous features to modify attack actions to avoid detection. Available attack actions include denial of service and privilege escalation. Their model is shown to drastically increase the evasion rate of malicious network traffic across several different classifiers when benchmarked using the NSL-KDD benchmark provided in \cite{Hu2015}.

Despite the successes of these works, no current GAN model has been applied to recreation or expansion of cyber-attack alert data. This research aims at recreating malicious NIDS samples from the victim perspective to solve this issue. Given the existing works using GAN to modify network traffic it is believable that GANs could also learn latent space representations for entire attack actions. 

\section{Summary}

The current research in applying Machine Learning to Cyber Security is well varied, but missing the application of generative models to new sample creation and analysis. This work applies state of the art GAN models to cyber alert data collected via the Suricata NIDS to fill this gap. The alerts used for training were collected from 10 student teams during an 8 hour long collegiate penetration testing competition (CPTC) as they attacked identical, isolated, instances of the same network topography. Two different years of competition data were tested independently, each representing different network topographies and attacker behaviors; additionally, illustrating the ability of a single network topography to learn and capture many different data distributions. All data was processed to consider traffic a per target IP basis allowing for different models to be used to represent each potential target in the network. 

Unique preprocessing steps for handling cyber alert data, exhaustive model hyperparameter tuning, and methods of identifying generated sample fidelity are also provided. Namely, the usage of histogram intersection for n-tuple feature combinations is shown to be an effective and intuitive means of judging sample generation quality. Additionally, this metric may be coupled with joint and conditional entropy calculations to show dependencies between features of an alert, allowing for further introspection of attack behavior.

Finally, the application of Mutual Information Estimate Maximization to WGAN-GP is shown to improve sample generation by increasing the number of output modes captured by the generator. This model is referred to as WGAN-GPMI and is shown to improve generated results through a higher intersection of histograms and closer PMF approximation by the generator.

\chapter{Methodology}

\section{Cyber Alert Data Preprocessing}

\section{Methods of Analyzing Alert Data}

\subsection{Analyzing Fidelity of Data}

\subsection{Analyzing Relationships within Alert Data}

\chapter{Design Implementation}

\section{Model Architecture}

\subsection{Improving Model output through Mutual Information Contraints}

\section{Model Training}

\chapter{Results and Analysis}

\section{Judging the Fidelity of Generated Data}

\section{Visualizing Feature Relationships within Alerts}

\chapter{Conclusions and Future Work}

\section{Conclusion}

\section{Future Work}

\subsection{Multi-Alert Generation and Analysis}

\subsection{Improving Generations through Reinforcement Learning}

  ...
  \nocite{*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\renewcommand\refname{References}
%\renewcommand\bibname{References}
%\addto{\captionsamerican}{\renewcommand\bibname{References}}
\bibliographystyle{plain}
% Single space the bibliography to save space.
\begin{singlespace}
\bibliography{Thesis}
\end{singlespace}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% The appendices are (of course) optional.
\appendix
\chapter{Proof of Smooth Gradients from Hierarchical Scoring}
  ...
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
