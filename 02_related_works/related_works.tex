% background.tex
%
% Author       : James Mnatzaganian
% Contact      : http://techtorials.me
% Date Created : 08/27/15
%
% Description  : Background chapter used by "thesis.tex".
%
% Copyright (c) 2015 James Mnatzaganian

\chapter{Related Work}

With the recent resurgence of Machine Learning, and newfound abilities of Deep Learning models, researchers across a variety of domains have begun to apply these methods to outstanding challenges in their fields. Cyber-Security has not evaded this, as Deep Neural Networks have been used for cyber event classification, forecasting, malicious traffic modification, and now data generation. This section shall be organized as follows: First, a survey of existing applications of Machine Learning to Cyber Security problems will be reviewed to illustrate the need for rich alert datasets. Then advances in generative models from other fields will be examined to better understand how state of the art generative models achieve the results that they do. And finally, the current use case of generative models for cyber security will be compared to the methods proposed by this work. 

\section{Cyber Security and Machine Learning}

The predominant application of Machine Learning to Cyber Security has been focused on the challenge of anomaly detection, attack classification, and event prediction. For all of these tasks intricate relationships must be considered between the various features of alerts as well as entire chains of temporally connected alerts. 

In order to maintain these temporal relationships Recurrent Neural Networks have been employed. Specifically, Long Short Term Memory (LSTM) units allow for the network to learn how to weight the importance of prior events and when to forgot alerts entirely. These models have been applied to Cyber Physical Systems by Filonov \etal to identify anomalous behavior. Their results demonstrate the power of LSTM for Cyber Security as they outperform traditional methods such as PCA, FDA, DFDA, CVA and SVM based anomaly detection \cite{Filonov2016, Filonov2017} on the Numenta Anomaly Benchmark \cite{Lavin2015}

Other works make use of the aforementioned KDD Cup'99 dataset for cyber event classification. Both the works of Staudemeyer \etal \cite{Staudemeyer} and Kim \etal \cite{Kim} show that LSTM networks are able to achieve impressive results near $100\%$ accuracy when tasked with identifying if a stream of traffic is normal, or falls into one of the four malignant labels. 

This type of problem is echoed by Tuor \etal \cite{Tuor} who use system logs and a twin neural network model to identify if traffic is malignant. The first model extracts information from the past $24$ hours of system logs by embedding a mixture of categorical and event count features into a hidden representation. A series of these hidden representations are then fed into the second model, an LSTM network, which classifies potential cases of malignant behavior. Through the usage of a fixed sliding window the dataset may be continuously updated. This allows for a continuous training approach to be used, keeping models up to date regarding new system log behavior. 

Another such example would be $AI^2$ \cite{Veeramachaneni2016} which integrates expert input into the network traffic used for training an LSTM. The LSTM learns identify anomalous behavior which is then classified by a human analyst. The analyst's feedback is then given to the network and used for future parameter updates so that future events may be flagged with a higher degree of accuracy.

Other works have taken the challenge of prediction and classification a step further and attempted to forecast attributes of future attacks. One example of this is the work of Perry \etal \cite{us} who applied LSTMs to a collegiate penetration testing competition to see if alerts early in the competition could be used to identify which team was perpetrating an attack later on in the event. Further, they also showed that attributes of future attacks could be forecast, such as the alert signature (what) and destination port (where). 

Similarly Shen \etal \cite{Shen2018} applied LSTMs to a dataset of 3.4 billion security events collected from Symantec's Intrusion Prevention Product deployed on corporate networks which have opted in to it's data sharing program. Their results demonstrate that LSTM can be used to predict target machine, attack severity, and even specific common vulnerability exploits which may be used in the attack with over $80\%$ accuracy. 

All of these systems for attack classification and prediction make use of data collected via NIDS. Despite the promising results of each, several of the authors note that they believe and increased dataset would allow for them to further improve the accuracy of their models \cite{us, Faber2018, Shen2018}. 

\section{Generative Adversarial Networks: Models and Improvements}

First proposed by Goodfellow \etal \cite{Goodfellow2014}, GANs are a game theoretic model for generating increasingly realistic data in a semi supervised manner. The generator learns a set of nonlinear transformations ($T$) to apply to noise $\widehat{x}$ sampled from $\P_{\widehat{x}}$. These transformations result in data which imitates that of the ground truth set $x$ sampled from $\P_r$. The discriminator is fed both real,  $x$ sampled from $\P_r$, and generated, $\widetilde{x}$ sampled from $\P_g$, data and assigns a probability $p \in [0,1]$ representing the believed probability that a sample came from the distribution $\P_r$. 

Immediately GANs proved themselves to be a powerful tool for the generation of new samples in continuous value spaces such as images. Rapid advances came through the application of Conditional generation \cite{Mirza2014}, Deep Convolutional Networks \cite{Radford2015}, and Information Theoretic extensions \cite{Chen2016}. 

Simultaneously the training and structure of GANs were updated to improve convergence rates, palliate output mode dropping, and provide meaningful learning curves \cite{Salimans, Arjovsky2017, Gulrajani2017}. Most notably, the Wasserstein GAN proposed by Arjovsky \etal \cite{Arjovsky2017} introduced the usage of the Earthmover Distance as the loss function for both the generator and discriminator. Intuitively, this distance represents how much "mass" must be transported from x to y in order to transform $\P_g$ into $\P_r$. 

WGAN was subsequently improved by Gulrajani \etal \cite{Gulrajani2017} by adding a gradient penalty term (WGAN-GP) to regularize the gradients of D. The gradient penalty creates a 1-Lipschitz constraint on the discriminator during training by sampling noise $\widehat{x}$ from $\P_{\widehat{x}}$ and constraining the gradient of the L2 norm of D to 1. Additionally, the discriminator was given real samples and generated samples in a 5:1 ratio per epoch of training; this is done to increase the utility of gradients provided to the generator by discriminator. These modifications to training result in the loss formulation shown in (\ref{eq:WGAN-GP1}), (\ref{eq:WGAN-GP2}), and (\ref{eq:WGAN-GP3}) for the discriminator, the gradient penalty term, and the generator respectively:

\begin{align}
	D_{loss} &=  \E_{\widetilde{x} \thicksim \P_g}[D(\widetilde{x})] - \E_{x \thicksim \P_r}[D(x)] + \label{eq:WGAN-GP1} \\
	& \lambda \E_{\widehat{x} \thicksim \P_{\widehat{x}}}[(||\nabla_{\widehat{x}} D(\widehat{x})||_2 -1)^2] \label{eq:WGAN-GP2}\\
	G_{loss} &=  -\E_{\widetilde{x} \thicksim \P_g}[D(\widetilde{x})] \label{eq:WGAN-GP3}
\end{align}

\begin{equation}
	D_{KL}(P||Q) = \sup\limits_{T:\Omega \rightarrow \Reals} \E_\P[T] - \log(\E_\Q[e^T])
	\label{eq:MINE}
\end{equation}

Separate from the advances of WGAN and WGAN-GP, Mutual Information Neural Estimation (MINE) \cite{Belghazi2018} was introduced as a means to help palliate output mode dropping and improve reconstruction of generative models. MINE uses a neural network optimized using the Donsker-Varadhan representation of the KL-Divergence, given in (\ref{eq:MINE}), to estimate the mutual information $I$ between two distributions. They then show that this architecture may be used with GANs by using the Mutual Information estimate to regularize the generator's loss by simply adding the term $I(G([z];z))$. The results of adding such a term was the complete removal of mode dropping in several benchmarks.

\section{Applications of Generative Adversarial Networks to Network Traffic: Adversarial Sample Crafting}

One common application of GANs has been the creation of Adversarial Samples. First noted by Szegedy \etal \cite{Szegedy2013}, Adversarial Samples are generated by taking ground truth samples, applying a small, human-imperceptible, perturbation, resulting in that sample being misclassified by a neural network with a high degree of confidence. Subsequent research found more powerful ways to generate Adversarial Samples through methods such as fast gradient sign \cite{Goodfellow2015}, optimization based methods \cite{Carlini2017, Liu2017, Eykholt2018}, and GANs \cite{Xiao2018}. 

Advarsarial Sample Crafting has been applied to network traffic to modify and obfuscate malicious traffic \cite{Rigaki2018, Lin2018, Hu2017, Anderson2017}. These adversarial samples are created to avoid being flagged by Network Intrusion Detection Systems (NIDS).

Rigaki \etal \cite{Rigaki2018} proposed the use of GANs in generating network traffic which mimics other types of network traffic. In particular, real malware traffic was modified by a GAN to appear as legitimate network traffic. This allowed the malware to avoid detection from the Stratosphere Behavioral Intrusion Prevention System through the modification of three network traffic parameters; total byte size, duration of network flow, and time delta between current network flow and the last network flow. They showed that through the modification of these parameters detection rate could be dropped down to 0\%. 

Similarly, Lin \etal \cite{Lin2018} apply GANs to obfuscate traffic with the intention of directly deceiving a NIDS. Their model makes use of 9 discrete features and 32 continuous features to modify attack actions to avoid detection. Available attack actions include denial of service and privilege escalation. Their model is shown to drastically increase the evasion rate of malicious network traffic across several different classifiers when benchmarked using the NSL-KDD benchmark provided in \cite{Hu2015}.

Despite the successes of these works, no current GAN model has been applied to recreation or expansion of cyber-attack alert data. This research aims at recreating malicious NIDS samples from the victim perspective to solve this issue. Given the existing works using GAN to modify network traffic it is believable that GANs could also learn latent space representations for entire attack actions. 

\section{Summary}

The current research in applying Machine Learning to Cyber Security is well varied, but missing the application of generative models to new sample creation and analysis. This work applies state of the art GAN models to cyber alert data collected via the Suricata NIDS to fill this gap. The alerts used for training were collected from 10 student teams during an 8 hour long collegiate penetration testing competition (CPTC) as they attacked identical, isolated, instances of the same network topography. Two different years of competition data were tested independently, each representing different network topographies and attacker behaviors; additionally, illustrating the ability of a single network topography to learn and capture many different data distributions. All data was processed to consider traffic a per target IP basis allowing for different models to be used to represent each potential target in the network. 

Unique preprocessing steps for handling cyber alert data, exhaustive model hyperparameter tuning, and methods of identifying generated sample fidelity are also provided. Namely, the usage of histogram intersection for n-tuple feature combinations is shown to be an effective and intuitive means of judging sample generation quality. Additionally, this metric may be coupled with joint and conditional entropy calculations to show dependencies between features of an alert, allowing for further introspection of attack behavior.

Finally, the application of Mutual Information Estimate Maximization to WGAN-GP is shown to improve sample generation by increasing the number of output modes captured by the generator. This model is referred to as WGAN-GPMI and is shown to improve generated results through a higher intersection of histograms and closer PMF approximation by the generator.
