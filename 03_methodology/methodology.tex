\chapter{Methodology}

The usage of alert data with Machine Learning algorithms suffers from two issues; significant preprocessing must be performed to make the data have contextual meaning and methods to analyze the similarity of alerts are not well defined. For example, predicting a specific port which will be attacked only provides a small piece of significant data. However, a more significant feature to generate would be what type of service is typically run on a family of ports so that similar ports are grouped together. Additionally, when analyzing cyber alerts identifying the fidelity of data is not straight forward. In tasks such as event prediction results may be quantified by cross entropy loss on a per feature basis. But when generating new alerts there are complex interactions between various features which must be accounted for by the model. Simply generating \emph{a} realistic signature and port category is much less important than generating a realistic \emph{combination} of port signature and category. 

To address these challenges this section will cover the unique preprocessing applied to NIDS data collected from Suricata. Specifically, the features of alert signature, destination port, timestamp, and source IP will be considered. Additionally, intuitive metrics for analyzing alert fidelity are introduced as an inclusive system to address how realisitc generated alerts are compared to their source alerts from the ground truth dataset. 

\section{Cyber Alert Data Preprocessing}


The data used for these experiments comes from the National Collegiate Penetration Testing Competition from 2017 and 2018 (\texttt{https://nationalcptc.org/}). In 2017, teams were tasked with penetrating and exploiting network vulnerabilities in a virtualized network managing election systems. In 2018 teams were required to attack a multifaceted system handling autonomous cars which included host based systems, servers, and even mobile assets such as cell phones running an app. Each team had a total of 8 hours to scan, infiltrate, and exfiltrate information from the network. Both datasets provide a unique opportunity for Machine Learning experimentation as they are completely comprised of malicious actions as teams attempt to penetrate the target network. Though this data is unique to the competition it is worth noting that the preprocessing described herein is applicable to any dataset consisting of NIDS alerts.  

The first preprocessing step applied to the data was to separate alerts on a per-destination/target IP basis. This allowed individual models to be trained for each system on the network, typifying the type of traffic seen at that node. Additionally, data from all of the teams could be compounded, allowing for the number of potential attacks taken on a single target to be more fully expressed during training. Segmentation on a per-target basis has several intuitive benefits: First, it allows for different vulnerabilities to be highlighted on each machine given commonly occurring alert features at that target. Secondly, it helps to remove noisy alert influence from critical nodes in the network. For example, internet facing IPs may contain a significant amount of scanning activity, drowning out exfiltration related alert features at nodes further embedded in the network. Finally, the information extracted from alerts on a per target basis is actionable, as network administrators can use commonly targeted vulnerabilities to tune network settings for future defenses. 

% TODO: Numbers are for CPTC17 only -update with table

Next, the dimensionality of the destination port feature was reduced based off common service categories run across a collection of ports provided by the Internet Assigned Numbers Authority \cite{iana}. This reduction drops the number of unique values from 1516 destination ports to 69 destination port categories. Additionally, the dimensionality reduction step can easily be expanded or customized on a per network basis given a corporation's configuration of services. 

% TODO: Duplicate alerts are removed for 17, but not for 18. -retest


Finally, a set of simple statistical criterion are used to segment timestamps into bins. Traditional modeling of cyber attacks use killchain stages to segment actions into a series of contiguous stages with dependencies on previous stages. The beginning of an attack may consist of Reconnaissance based actions, yielding information about which IP to target in later attack stages. Similarly, the CPTC dataset may be segmented to try and capture unique behaviors into different bins of time. 

Following the methodology shown by \cite{us} bins are generated by smoothing the histogram timestamps and taking the first derivative to identify local minima and maxima. Then stages are cut if they contain at least $10\%$ of the total data and consecutive events at the candidate point contain less than $0.5\%$ of the total data. The goal of this ruleset is to capture significantly different types of traffic that does not split bursts of data into multiple stages. This process is shown visually in Fig. \ref{fig:cut_process}.

% TODO: Add figures showing the cut process



\section{Methods of Analyzing Alert Data}

\subsection{Analyzing Fidelity of Data}

\subsection{Analyzing Relationships within Alert Data}
