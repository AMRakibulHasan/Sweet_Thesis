\chapter{Results and Analysis}
\label{sec:rna}

% TODO: Include mention that this spans across 17 and 18 data.

Each of the GAN models described in Section \ref{sec:model_arch} were used to create artificial NIDS alert data.  Using the methods described in Section \ref{sec:anal} the fidelity of the learned model was analyzed. This analysis can be broken down into the following sections:

\begin{enumerate}
	\item Thorough Hyperparameter Search - Individual hyperparameters were tuned for each model to see their impact on histogram intersection. Top candidate values were selected for a full hyperparameter search where all combinations of hyperparameter values were tested. The results are presented for both WGAN-GP and the improved WGAN-GPMI.

	\item Alert Fidelity - A subset of target IPs from the CPTC'17 dataset were used for training WGAN-GP and WGAN-GPMI models. The results of these models were analyzed and visualized using Histogram Intersection and Jensen-Shannon Divergence.

	\item Alert Dependency - For the same subset of target IPs alert dependencies were identified by using drop in histogram intersection, entropy computation, and conditional probability tables.

	\item Output Modes Captured - The number of output modes captured by the model is comprised of two components. How many of the true output modes are output by the model? And how many output modes by the model do not occur in the ground truth?

	\item Generality of Models - To show the ability of these models to perform on a variety of datasets we introduce the CPTC'18 dataset. Histogram Intersection and Jensen Shannon Divergence are used to measure the performance of each model when trained on a new dataset.

\end{enumerate}

The CPTC'17 dataset was segmented on per-target IP basis and used across all experiments. For the hyperparameter search the IP which contained the most alerts, 10.0.0.100, was used. For the following experiments on alert fidelity, modeling dependency, and output modes captured the following four IP's were used: 10.0.0.100, 10.0.0.22, 10.0.0.27, 10.0.99.143. These four IP addresses provided a mixture of Windows and Linux Machines, with varying purpose, and contained the 4 greatest counts of alerts. Table. \ref{tab:mapping} summarizes the differences between each of these machines.

\begin{table}[!htbp]
	\caption{Mapping of Target IP Address to Machine Usage/Purpose}
	\label{tab:mapping}
	\centering
	\begin{tabular}{c|c|c|c}
		\textbf{IP Address} & \textbf{Operating System} & \textbf{Machine Usage} & \textbf{Number of Alerts}\\
		\hline
		10.0.0.100 & Windows & Active Directory Server & 3388\\
		\hline
		10.0.0.27 & Ubuntu & HTTP Server & 3166\\
		\hline
		10.0.0.22 & Ubuntu & MySQL Server & 2974\\
		\hline
		10.0.99.143 & Ubuntu & HTTP Server & 2182
	\end{tabular}
\end{table}

It was important to consider the machines with the greatest number of alerts as Deep Learning, especially for GANs, requires very large datasets.

\section{Thorough Hyperparameter Search}
\label{sec:search}
A two part hyperparameter search was employed to find optimal values for generating alerts from the CTPC datasets. First, individual parameters were tested in order to find several values which resulted in promising results. For each parameter value tested, the histogram intersection was computed for all possible feature-value combinations. These values were then plotted against all other parameter setting results for WGAN-GP and WGAN-GPMI. To save space in the plots each feature combination was assigned a numeric key. Table \ref{tab:key} provides the key mapping to each potential feature combination. 

\begin{table}[!htbp]
	\caption{Key for Feature Combinations}
	\label{tab:key}
	\centering
	\begin{tabular}{l|c}
		\textbf{Feature Combination} & \textbf{ID} \\ \hline
		Alert Signature & 0 \\
		Time Bin & 1 \\
		Destination Service & 2 \\
		Source IP & 3 \\
		Alert Signature, Destination Service & 4 \\
		Source IP, Time Bin & 5 \\
		Alert Signature, Source IP & 6 \\
		Alert Signature, Time Bin & 7 \\
		Destination Service, Time Bin & 8 \\
		Source IP, Destination Service & 9 \\
		Alert Signature, Source IP, Time Bin & 10 \\
		Source IP, Destination Service, Time Bin & 11 \\
		Alert Signature, Source IP, Destination Service & 12 \\
		Alert Signature, Destination Service, Time Bin & 13 \\
		Alert Signature, Source IP, Destination Service, Time Bin & 14
	\end{tabular}
\end{table}

Then, these values were taken and used for a full parameter sweep, which tested every possible combination of the parameter values available. Several candidate values were selected for each of the hyperparameters due to the unknown nature of hyperparameter interaction.

This two stage search was carried out twice, once for each of the GAN models presented in Section \ref{sec:model_arch}. Both models only used data from the target IP with the most number of alerts, 10.0.0.100, to try and avoid information constraints related to small dataset size. The parameters tested included lambda, batch size, learning rate, hidden dimension, and number of epochs.

\subsection{Lambda}
\label{sec:lam}
The lambda parameter was used as a coefficient to the gradient penalty term applied to the discriminator. The values tested for lambda were $\{0.05, 0.1, 0.2, 0.3, 0.4\}$. The intersection vs. parameter setting plots for WGAN-GP and WGAN-GPMI may be seen in Fig. \ref{fig:wgan_lam} and Fig. \ref{fig:gpmi_lam} respectively.

\begin{figure}[!htbp]
	\centering

	\begin{subfigure}{.7\textwidth}
		\includegraphics[width=\textwidth]{wgan_lam}
	\end{subfigure}%
	\begin{subfigure}{.3\textwidth}
		\caption{
			All other hyperparameters were held constant at the following values: $epochs=180$, $batch\_size = 100$, $learning\_rate=5e-5$, $hidden\_dimension=128$
		}
		\label{fig:wgan_lam}
	\end{subfigure}%

	\begin{subfigure}{.7\textwidth}
		\includegraphics[width=\textwidth]{gpmi_lam}
	\end{subfigure}%
	\begin{subfigure}{.3\textwidth}
		\caption{
			All other hyperparameters were held constant at the following values: $epochs=250$, $batch\_size=100$, $learning\_rate=5e-4$, $hidden\_dimension=128$
		}
		\label{fig:gpmi_lam}
	\end{subfigure}%
	\caption{Lambda Parameter Search}
\end{figure}

The performance of all the values tested was very close. For the WGAN-GP model smaller values such as $\{0.05, 0.1, 0.2\}$ performed best. In the WGAN-GPMI model the larger values tested, $\{0.2,0.3,0.4\}$ performed best. This suggests that the WGAN-GPMI model requires stronger enforcement of the gradient penalty than the WGAN-GP model does. Given that the gradient of the generator is changed from an outside source (the mutual information estimate) in addition to the discriminator feedback, the discriminator may be trying to make larger gradient changes to identify generated samples.

\subsection{Batch Size}
\label{sec:bs}

The batch size determines how many alert samples were fed into the model in parallel. Higher batch sizes are more computationally intensive, but provide a better representation of the ground truth data distribution. Additionally, larger batch sizes reduce the number of steps required to complete a full epoch of training.

The values tested for batch size were $\{10, 25, 50, 100, 150, 250, 500, 1000\}$. The intersection vs. parameter setting plots for WGAN-GP and WGAN-GPMI may be seen in Fig. \ref{fig:wgan_batch_size} and Fig. \ref{fig:gpmi_batch_size} respectively.

\begin{figure}[!htbp]
	\centering
	\begin{subfigure}{.7\textwidth}
		\includegraphics[width=\textwidth]{wgan_batch_size}
	\end{subfigure}%
	\begin{subfigure}{.3\textwidth}
		\caption{
			All other hyperparameters were held constant at the following values: $epochs=180$, $learning\_rate=5e-5$, $hidden\_dimension=128$, $\lambda=0.1$
		}
		\label{fig:wgan_batch_size}
	\end{subfigure}%

	\begin{subfigure}{.7\textwidth}
		\includegraphics[width=\textwidth]{gpmi_batch_size}
	\end{subfigure}%
	\begin{subfigure}{.3\textwidth}
		\caption{
			All other hyperparameters were held constant at the following values: $epochs=250$, $learning\_rate=5e-4$, $hidden\_dimension=128$, $\lambda=0.3$
		}
		\label{fig:gpmi_batch_size}
	\end{subfigure}%
	\caption{Batch Size Parameter Search}
\end{figure}

The overall range and trends of intersection scores are very similar for both WGAN-GP and WGAN-GPMI. It is interesting to observe that for the WGAN-GPMI model that the performance drop after using batch sizes greater than 250 is much greater than that of the WGAN-GP model. This is likely due to additional network generating the mutual information estimate. This network is trained in parallel with the WGAN model, thus earlier steps in training may have poor mutual information estimates. Since larger batch size drives less gradient updates over the same number of epochs there is a larger number of inaccurate mutual information estimates provided to the WGAN portion of the model. The top selections for the full parameter search are $\{10,25,50,100,150\}$ for the WGAN model and $\{50,100\}$ for the WGAN-GPMI model.

\subsection{Learning Rate}
\label{sec:lr}

The learning rate of the optimizer defines the base step size, weighted by the gradient of the loss, that is taken when adjusting parameter weights during training. A large learning rate converges quickly, but may overshoot the global optimum and never reach peak performance. A small learning rate won't overshoot the global optimum, however will take significantly longer to converge. Due to the categorical output of alert data and existing difficulty in optimizing GANs, small learning rates were tested. This allowed the network to be able to make fine tuned changes to network weights, as slight changes in output probability create entirely different output values. Additionally, the ADAM optimizer was used, allowing for weight decay over time to modify the learning rate parameter.


The values tested for learning rate were $\{1e-5, 5e-5, 1e-4, 5e-4, 1e-3\}$. The intersection vs. parameter setting plots for WGAN-GP and WGAN-GPMI may be seen in Fig. \ref{fig:wgan_lr} and Fig. \ref{fig:gpmi_lr} respectively.

\begin{figure}[!htbp]
	\centering
	\begin{subfigure}{.7\textwidth}
		\includegraphics[width=\textwidth]{wgan_lr}
	\end{subfigure}%
	\begin{subfigure}{.3\textwidth}
		\caption{
			All other hyperparameters were held constant at the following values: $epochs=180$, $batch\_size = 100$, $hidden\_dimension=128$, $\lambda=0.1$
		}
		\label{fig:wgan_lr}
	\end{subfigure}%

	\begin{subfigure}{.7\textwidth}
		\includegraphics[width=\textwidth]{gpmi_lr}
	\end{subfigure}%
	\begin{subfigure}{.3\textwidth}
		\caption{
			All other hyperparameters were held constant at the following values: $epochs=250$, $batch\_size=100$, $hidden\_dimension=128$, $\lambda=0.3$
		}
		\label{fig:gpmi_lr}
	\end{subfigure}%
	\caption{Learning Rate Parameter Search}
\end{figure}

For both of the models tested, the smallest learning rate $1e-5$ performs poorly. Interestingly, in the WGAN-GP model the subsequent three learning rates $\{5e-5,1e-4,5e-4\}$ oscillate between performing well and poorly. due to this oscillations $1e-4$ is dropped, leaving $\{5e-5,5e-4,1e-3\}$ for the full parameter search. For the WGAN-GPMI model $\{1e-4, 5e-4, 1e-3\}$ are all used in the full parameter test.


\subsection{Hidden Dimension}
\label{sec:hdim}

The hidden dimension size determines the number of hidden units available in each hidden layer. Higher hidden dimensions provide more learnable connections to the network allowing the network to learn complex approximations. On the other hand, larger hidden dimension sizes leads to potential overfitting and raises the computational complexity of training the network.

The values tested for hidden dimension were $\{64, 128, 256, 384, 512\}$. The intersection vs. parameter setting plots for WGAN-GP and WGAN-GPMI may be seen in Fig. \ref{fig:wgan_hdim} and Fig. \ref{fig:gpmi_hdim} respectively.

\begin{figure}[!htbp]
	\centering
	\begin{subfigure}{.7\textwidth}
		\includegraphics[width=\textwidth]{wgan_hdim}
	\end{subfigure}%
	\begin{subfigure}{.3\textwidth}
		\caption{
			All other hyperparameters were held constant at the following values: $epochs=180$, $batch\_size = 100$, $learning\_rate=5e-5$, $\lambda=0.1$
		}
		\label{fig:wgan_hdim}
	\end{subfigure}%

	\begin{subfigure}{.7\textwidth}
		\includegraphics[width=\textwidth]{gpmi_hdim}
	\end{subfigure}%
	\begin{subfigure}{.3\textwidth}
		\caption{
			All other hyperparameters were held constant at the following values: $epochs=250$, $batch\_size=100$, $learning\_rate=5e-4$, $\lambda=0.3$
		}
		\label{fig:gpmi_hdim}
	\end{subfigure}%
	\caption{Hidden Dimension Parameter Search}
\end{figure}


The range of histogram intersection scores for the hidden parameter search is far smaller than the other hyperparameters. For the WGAN-GP model $\{128, 256, 384\}$ had the highest intersection scores, while $\{64,128,256\}$ performed well for the WGAN-GPMI model.


\subsection{Epochs}
\label{sec:epoch}

The number of epochs determined how many times the network was exposed to the full dataset during training. Using a large number of epochs allows for the network to get more exposure to the ground truth distribution. However using a very large number of epochs can lead to overfitting.

Due to the small size of the CPTC dataset, large values for epochs were tested. These values included $\{50, 100, 150, 200, 250\}$. The intersection vs. parameter setting plots for WGAN-GP and WGAN-GPMI may be seen in Fig. \ref{fig:wgan_epoch} and Fig. \ref{fig:gpmi_epoch} respectively.

\begin{figure}[!htbp]
	\centering
	\begin{subfigure}{.7\textwidth}
		\includegraphics[width=\textwidth]{wgan_epoch}
	\end{subfigure}%
	\begin{subfigure}{.3\textwidth}
		\caption{
			All other hyperparameters were held constant at the following values: $batch\_size = 100$, $learning\_rate=5e-5$, $hidden\_dimension=128$, $\lambda=0.1$
		}
		\label{fig:wgan_epoch}
	\end{subfigure}%

	\begin{subfigure}{.7\textwidth}
		\includegraphics[width=\textwidth]{gpmi_epoch}
	\end{subfigure}%
	\begin{subfigure}{.3\textwidth}
		\caption{
			All other hyperparameters were held constant at the following values: $batch\_size=100$, $learning\_rate=5e-4$, $hidden\_dimension=128$, $\lambda=0.3$
		}
		\label{fig:gpmi_epoch}
	\end{subfigure}%
	\caption{Epochs Parameter Search}
\end{figure}

Increasing the number of epochs is critical for the WGAN-GPMI model to perform well. This makes intuitive sense, as this model requires the optimization of three neural networks. The $30$ epochs test case highlights this, as nearly all 3-tuple and 4-tuple feature combinations have 0 intersection with the ground truth distribution. Comparatively, the WGAN-GP model is able to achieve results within the range of $20-30$ percent; still the worst result of the values tested, but significantly better than WGAN-GPMI. For the WGAN-GP model, $\{100,150,200\}$ epochs were selected for the full hyperparameter sweep. For the WGAN-GPMI model, $\{150, 200, 250\}$ were selected.

\subsection{Full Parameter Sweep}

Collecting the candidate values from Sections \ref{sec:lam} through \ref{sec:epoch}, a full parameter search was carried out to test all combinations of these values. The values under test for each model may be seen in Table \ref{tab:param_sweep}, along with the unique number of combinations tested.

\begin{table}[!htbp]
	\centering
	\caption{Candidate Parameters for WGAN-GP and WGAN-GPMI}
	\label{tab:param_sweep}
	\begin{tabular}{l|ccccc|l|cccl}
		\cline{1-11}
		\multicolumn{6}{c}{\textbf{WGAN-GP Parameters}} & \multicolumn{1}{l}{} & \multicolumn{4}{c}{\textbf{WGAN-GPMI Parameters}} \\
		\cline{1-11}
		Lambda & 0.05 & 0.1 & 0.2 & & & & 0.2 & 0.3 & 0.4 & \\
		Batch Size & 10 & 25 & 50 & 100 & 150 & & 50 & 100 &  & \\
		Learning Rate & 5e-5 & 5e-4 & 1e-3 & & & & 5e-5 & 1e-4 & 5e-4 & 1e-3 \\
		Hidden Dimension & 128 & 256 & 384 & & & & 64 & 128 & 256 & \\
		Epochs & 100 & 150 & 200 & & & & 150 & 200 & 250 & \\
		\cline{1-11}
		\multicolumn{3}{l|}{Number of Unique Combinations} & \multicolumn{3}{c}{405} & \multicolumn{1}{|l|}{} & \multicolumn{4}{c}{216} \\ \cline{1-11}
	\end{tabular}
\end{table}

For each parameter combination tested the intersection of histograms for all feature combinations was computed and tabulated. Given number of unique combinations tested a simple 3 step heuristic was defined to help identify the combinations which performed well in the table. For each combination of features:

\begin{enumerate}
	\item The highest intersection score achieved was highlighted in yellow.
	\item Intersection scores that fell within the $90^{th}$ percentile were highlighted in green
	\item Intersection scores that fell within the $80^{th}$ percentile were highlighted in red.
\end{enumerate}

This system reduced the search of possible combinations, and allowed for quick visual identification of values which performed well. Identifying the highest intersection score per feature combination is not sufficient criteria to identify the best hyperparameter combination as scores are very close and can be noisy. Adding in the $90^{th}$ constraint helps to identify other candidates with high performing intersection scores. Finally, the $80^{th}$ percentile constraint is meant to act as a lower bound as values which fall within in it are still good, and values which are not highlighted at all should raise questions about model performance. For example, if the individual feature intersections are within the $90^{th}$ percentile but 3-tuple and 4-tuple combinations are completely not highlighted, the model may have failed to capture high order dependencies in the distribution of the data. Thus, that parameter setting should not be considered for use in future experiments.

A subsection of the highlighted table for the WGAN-GPMI model is given in Fig. \ref{fig:highlighted_param_gpmi}. Note that the row with the red arrow pointing to it performs well, as 6 of it's 15 values are the highest performing intersection scores with an additional 6 in the $90^{th}$ percentile. The only feature which fails to achieve an intersection score within the $80^{th}$ percentile is Destination Service. Table \ref{tab:params} shows the optimal hyperparameter values selected for each model. Despite only testing on a single target IP address, these parameters were applied to all other target IP addresses and performed well.

\begin{figure}[!htbp]
	\centering
	\includegraphics[width=\textheight,height=.85\textwidth,angle=90]{gpmi_full_param_search}
	\caption{
		Subsection of WGAN-GPMI Hyperparameter Search Results
	}
	\label{fig:highlighted_param_gpmi}
\end{figure}

\begin{table}[!htb]
	\centering
	\caption{Optimal Hyperparameter Settings}
	\label{tab:params}
	\begin{subtable}{.5\linewidth}
		\centering
		\caption{}
		\begin{tabular}{l|l}
			\hline
			\multicolumn{2}{c}{\textbf{WGAN-GP}} \\
			\hline
			Epochs & 150 \\
			Batch Size & 100 \\
			Learning Rate & 5e-4 \\
			Lambda & 0.1 \\
			Hidden Dimension & 128
		\end{tabular}
	\end{subtable}%
	\begin{subtable}{.5\linewidth}
		\centering
		\caption{}
		\begin{tabular}{l|l}
			\hline
			\multicolumn{2}{c}{\textbf{ WGAN-GPMI}} \\
			\hline
			Epochs & 250 \\
			Batch Size & 100 \\
			Learning Rate & 5e-4 \\
			Lambda & 0.4 \\
			Hidden Dimension & 128
		\end{tabular}
	\end{subtable}%
\end{table}

\section{Alert Fidelity}
\label{sec:fidel}

Two metrics were employed in order to identify the fidelity of alert generation. Each metric was scaled such that it could be used to analyze individual feature performance as well as m-tuple combinations of features. This allowed for both low and high level performance of the model to be assessed. These metrics were the Histogram Intersection and Jensen Shannon Divergence.

\subsection{Histogram Intersection}
\label{sec:inter}

The histogram intersection was computed for all feature combinations across all 4 IP addresses tested. For each IP, all possible combinations of features were analyzed. This resulted in 4 intersections representing the individual features, 6 representing pairs of features, 4 representing 3-tuples, and a single histogram representing 4-tuple combinations.

Fig. \ref{fig:inter} steps through these levels of combinations for target 10.0.0.100. The top left plot shows the intersection of Time Bins. The top right plot shows the histogram combination of Time Bins and Destination Service. The bottom right adds the Alert Signature feature to the histogram. And finally, the bottom right shows all 4 features under test as a single joint histogram. It is important to note that as the number of features considered in the combination increases so does the complexity of recreating the data with high fidelity; individual occurrences of features drops, while the number of unique features to output rises.


\begin{figure}[!htbp]
	\centering
	\includegraphics[width=\textwidth]{10_0_0_100_inter_gpmi}
	\caption{
		Histogram Intersection for M-Tuple Feature Combinations
	}
	\label{fig:inter}
\end{figure}

The histogram intersection was used to analyze the fidelity of results from both of the models tested. In general, the WGAN-GPMI is able to outperform the standard WGAN-GP model. This suggests that the mutual information constraint results in a model which manages to emulate the ground truth distribution with a higher degree of accuracy than standard models are. Table \ref{tab:inter} summarizes the results of both models across all 4 target IP addresses.

\begin{table}[!htbp]
	\caption{Histogram Intersection for all Feature Combinations}
	\label{tab:inter}
	\centering
	\begin{adjustbox}{angle=90}
	\begin{tabular}{l|c|c|c|c|c|c|c|c|c|}
		\multicolumn{1}{c|}{} & \multicolumn{9}{c|}{\textbf{Victim Machine IP Address}} \\
		\multicolumn{1}{c|}{} & \multicolumn{4}{c|}{\textbf{WGAN-GP}} &  & \multicolumn{4}{c|}{\textbf{WGAN-GPMI}} \\
		\multicolumn{1}{c|}{\textbf{Features}} & \textbf{10.0.0.100} & \textbf{10.0.0.27} & \textbf{10.0.0.22} & \textbf{10.0.99.143} & \textbf{} & \textbf{10.0.0.100} & \textbf{10.0.0.27} & \textbf{10.0.0.22} & \textbf{10.0.99.143} \\ \hline
		\textbf{A} & 0.697 & 0.658 & 0.844 & 0.858 &  & 0.890 & 0.833 & 0.847 & 0.808 \\
		\textbf{D} & 0.772 & 0.660 & 0.843 & 0.905 &  & 0.899 & 0.846 & 0.823 & 0.827 \\
		\textbf{S} & 0.717 & 0.867 & 0.846 & 0.843 &  & 0.906 & 0.909 & 0.755 & 0.881 \\
		\textbf{T} & 0.814 & 0.760 & 0.818 & 0.723 &  & 0.892 & 0.815 & 0.844 & 0.819 \\ \hline
		\textbf{A,T} & 0.668 & 0.630 & 0.741 & 0.630 &  & 0.774 & 0.774 & 0.754 & 0.717 \\
		\textbf{A,S} & 0.634 & 0.590 & 0.774 & 0.757 &  & 0.791 & 0.747 & 0.718 & 0.771 \\
		\textbf{S,D} & 0.698 & 0.598 & 0.768 & 0.779 &  & 0.829 & 0.758 & 0.715 & 0.800 \\
		\textbf{D,T} & 0.710 & 0.631 & 0.768 & 0.659 &  & 0.790 & 0.777 & 0.736 & 0.726 \\
		\textbf{S,T} & 0.710 & 0.702 & 0.741 & 0.698 &  & 0.778 & 0.791 & 0.701 & 0.782 \\
		\textbf{A,D} & 0.693 & 0.637 & 0.828 & 0.830 &  & 0.825 & 0.822 & 0.820 & 0.777 \\ \hline
		\textbf{A,S,T} & 0.599 & 0.558 & 0.686 & 0.580 &  & 0.655 & 0.727 & 0.683 & 0.632 \\
		\textbf{A,S,D} & 0.627 & 0.573 & 0.761 & 0.734 &  & 0.733 & 0.737 & 0.697 & 0.740 \\
		\textbf{A,D,T} & 0.653 & 0.615 & 0.756 & 0.612 &  & 0.715 & 0.731 & 0.731 & 0.685 \\
		\textbf{S,D,T} & 0.611 & 0.569 & 0.690 & 0.597 &  & 0.652 & 0.734 & 0.632 & 0.635 \\ \hline
		\textbf{A,S,D,T} & 0.584 & 0.548 & 0.601 & 0.571 &  & 0.607 & 0.718 & 0.626 & 0.615 \\
	\end{tabular}
	\end{adjustbox}
\end{table}

%It is interesting to note that the intersection scores for all $m$-tuples are most similar between victim IP 10.0.0.22 and 10.0.99.143. Recall that IP 10.0.0.22 was a MySQL Server while 10.0.99.143 was a HTTP Server. Victim IP 10.0.0.27 was also identified as a HTTP Server, however, it's intersection scores were significantly lower than the other HTTP server, 10.0.99.143. A possible explanation of this observation is that 10.0.99.143 is on a different subnet and perhaps behind a different firewall, thus a more targetted set of attack actions were taken on it. This would cause there to be less diversity in the ground truth distribution, making it easier for either model to learn to emulate the ground truth distribution. This result points towards latent features of the network topography having a strong influence on the degree to which each model can learn to recreate data.

It is interesting to note that the effect of the mutual information constraint varies from Target IP address to Target IP address. For example, Target 10.0.0.22 only has small improvements to histogram intersection when adding using the WGAN-GPMI model. In several cases, such as Source IP and Destination Service, the intersection score actually drops. On the other hand Target IP addresses such as 10.0.0.27 see a large benefit from using the mutual information constraint. On average, the histogram intersection is $14.63$\% higher for the WGAN-GPMI model than it's WGAN-GP counterpart. 

Another interesting result of Table \ref{tab:inter} is that the intersection of histograms is resilient to earlier score bias. Consider the intersection score of Timestamp (T) on victim IP 10.0.0.100. This feature has the highest score of any single feature, potentially leading to the fallacious expectation that any combination with T will also score high. When moving to testing 2-tuple combinations such as Timestamp (T) and Alert Signature (A) however the intersection drops significantly. This leads to another interesting observation; the histogram intersection is monotonically decreasing with respect to it's constituent features. Intuitively this makes sense as adding new features to the combination cannot add any more information than what is contained in the constituent features. 

\subsection{Jensen Shannon Divergence}

Due to the shortcomings of histogram intersection discussed in Section \ref{sec:fidel} the Jensen Shannon Divergence is also computed for each model. Table \ref{tab:jsd} shows the results of this computation. Note that the Jensen Shannon Divergence does not have an upper bound like the histogram intersection does, however it's result can be interpreted as the amount of information required, in nats, to get from one distribution to another. For completely disparate distributions, the divergence is high, as a large amount of information is required to get from one distribution to the other. Histograms that have a similar probability distribution how a low amount of divergence, as less information is required to get from one distribution to another. Note that the Jensesn Shannon Divergence follows a reverse trend from the histogram intersection. Simply put, lower divergences are better than higher divergences. 

One of the largest benefits of the Jensen Shannon Divergence is that it imposes a nonlinear penalty based off the difference in histogram probability distributions. Directly applied to each of the models presented here, a large penalty is incurred if the model fails to output a value that occurs with non-zero probability in the ground truth. This benefit is especially apparent for Target IP 10.0.0.100 where the Jensen Shannon Divergence shows a greater improvement 4-tuple results when using the WGAN-GPMI model than the Histogram Intersection does. This will be further highlighted in Section \ref{sec:output} where the number of output modes is shown to double when using the WGAN-GPMI model. 

\begin{table}[!htbp]
	\caption{Jensen Shannon Divergence (nats) for all Feature Combinations}
	\label{tab:jsd}
	\centering
	\begin{adjustbox}{angle=90}
		\begin{tabular}{l|c|c|c|c|c|c|c|c|c|}
			\multicolumn{1}{c|}{} & \multicolumn{9}{c|}{\textbf{Victim Machine IP Address}} \\
			\multicolumn{1}{c|}{} & \multicolumn{4}{c|}{\textbf{WGAN-GP}} &  & \multicolumn{4}{c|}{\textbf{WGAN-GPMI}} \\
			\multicolumn{1}{c|}{\textbf{Features}} & \textbf{10.0.0.100} & \textbf{10.0.0.27} & \textbf{10.0.0.22} & \textbf{10.0.99.143} & \textbf{} & \textbf{10.0.0.100} & \textbf{10.0.0.27} & \textbf{10.0.0.22} & \textbf{10.0.99.143} \\ \hline
			\textbf{A} & 0.111 & 0.088 & 0.033 & 0.024 &  & 0.017 & 0.031 & 0.031 & 0.033 \\
			\textbf{D} & 0.052 & 0.086 & 0.032 & 0.012 &  & 0.006 & 0.026 & 0.041 & 0.021 \\
			\textbf{S} & 0.085 & 0.022 & 0.029 & 0.017 &  & 0.010 & 0.014 & 0.037 & 0.011 \\
			\textbf{T} & 0.049 & 0.047 & 0.028 & 0.060 &  & 0.009 & 0.030 & 0.019 & 0.023 \\ \hline
			\textbf{A,T} & 0.150 & 0.128 & 0.063 & 0.131 &  & 0.077 & 0.067 & 0.080 & 0.071 \\
			\textbf{A,S} & 0.145 & 0.150 & 0.070 & 0.071 &  & 0.059 & 0.076 & 0.067 & 0.063 \\
			\textbf{S,D} & 0.107 & 0.141 & 0.071 & 0.054 &  & 0.036 & 0.063 & 0.078 & 0.041 \\
			\textbf{D,T} & 0.121 & 0.126 & 0.063 & 0.126 &  & 0.069 & 0.063 & 0.091 & 0.063 \\
			\textbf{S,T} & 0.102 & 0.082 & 0.073 & 0.077 &  & 0.049 & 0.053 & 0.096 & 0.039 \\
			\textbf{A,D} & 0.142 & 0.110 & 0.044 & 0.054 &  & 0.060 & 0.050 & 0.047 & 0.055 \\ \hline
			\textbf{A,S,T} & 0.189 & 0.181 & 0.119 & 0.193 &  & 0.146 & 0.110 & 0.158 & 0.136 \\
			\textbf{A,S,D} & 0.173 & 0.169 & 0.080 & 0.100 &  & 0.102 & 0.092 & 0.081 & 0.082 \\
			\textbf{A,D,T} & 0.173 & 0.141 & 0.072 & 0.157 &  & 0.113 & 0.081 & 0.095 & 0.090 \\
			\textbf{S,D,T} & 0.174 & 0.178 & 0.114 & 0.197 &  & 0.141 & 0.106 & 0.160 & 0.132 \\ \hline
			\textbf{A,S,D,T} & 0.209 & 0.194 & 0.121 & 0.213 &  & 0.178 & 0.122 & 0.164 & 0.150 \\
		\end{tabular}
	\end{adjustbox}
\end{table}


\section{Alert Dependencies}
\label{sec:depend}

Interactions between NIDS alert features provide important contextual information about cyber attacks. For example, knowing what machine an attack will occur on can reduce the number of possible attack vectors on that machine. Capturing these feature dependencies is a key aspect of understanding the quality of the generative model. To verify these dependencies the drop in histogram intersection is noted, weighted conditional entropy is computed according to the equations provided by (\ref{eq:wce}) and (\ref{eq:norm_wce}), and joint entropy is computed using (\ref{eq:je}) and (\ref{eq:norm_je}) to provide a baseline. Conditional probability tables are also generated to provide detailed inspection of specific feature value relationships. Appendix \ref{sec:svm_app} contains an alternative method to verifying feature dependency through the usage of a Support Vector Machine. These metrics were all computed for both WGAN-GP and WGAN-GPMI models. 

\subsection{WGAN-GP Feature Dependency Performance}

By viewing the difference in histogram intersection between $m\pm1$ tuples, feature dependencies can be inferred. Large drops indicate a low amount of dependence between the lower levels of feature combinations and the higher level. Small drops when adding a new feature to the joint distribution indicate that there is dependence between the lower level combination and the newly added feature. By applying the graph structure given in Fig. \ref{fig:metric_graph} to NIDS alerts, histogram intersection scores can be noted in nodes of the graph while edges represent conditional and joint entropy. Fig. \ref{fig:alert_depend_1} shows the dependency graph for Target IP 10.0.0.27 from the CPTC'17 dataset. These graphs were constructed for the other three target IPs tested from CPTC '17 and are included in the Appendix \ref{sec:depend_app}

\begin{figure}[!htbp]
	\centering
	\includegraphics[width=.75\textwidth]{WGAN_27}
	\caption{
		Target 10.0.0.27 Alert Dependency Graph: WGAN-GP Results
	}
	\label{fig:alert_depend_1}
\end{figure}

Stepping through the graph, nodes along the outer edges represent a single feature histogram. The values given are the histogram intersection between the ground truth and generated data distribution. As edges are traversed and meet, they are combined and arrive at the next node as a combination of the features considered. This process continues inwards, adding one more unique feature to each joint distribution, until all four features are considered at once.

It is important to note that for the 2-tuple combinations there are actually 6 possible distributions, however only 4 may be visualized while maintaining planarity of the graph; the analysis of these values is still included in the conditional and joint probability tables.

In order to highlight drops in intersection score, the following schema was applied to the graph: Lines are color coded such that blue lines indicate feature unions which result in less than 5\% difference between histogram scores. Conversely, lines which are red indicate an difference that is greater than 5\%. Lines which are purple indicate a unidirectional dependence relationship between the feature tuples. This occurs when one feature is a good predictor of another ($<$ 5\% intersection difference) but the opposite is not true ($>$ 5\% intersection difference). Lines which are blue or red exhibit bidirectional dependence; both lines exhibit the same intersection difference. All dashed lines are bounding boxes added to clearly segment the varying $m$-tuple histograms.

To verify that the graph correctly highlights feature dependencies Table \ref{tab:ce} was computed. This table considers all unique permutations of features for all m-tuples across all 4 target IPs. The conditional entropy is then compared between the ground truth and generated data distributions. Additionally, the joint entropy was computed in Table \ref{tab:je} to provide a baseline representation of the amount of randomness in the feature distributions. This table contains calculations only from 2-tuple, 3-tuple, and 4-tuple combinations as there is no direct comparison to draw between conditional and joint entropy for single feature histograms.


\begin{table}[!htbp]
	\caption{Weighted Normalized Conditional Entropy Values for all Target IPs: WGAN-GP Result}
	\label{tab:ce}
	\centering
	\begin{adjustbox}{angle=90}
		\begin{tabular}{l|c|c|c|c|c|c|c|c|c|}
			\multicolumn{1}{c|}{} & \multicolumn{9}{c|}{\textbf{Victim Machine IP Address}} \\
			\multicolumn{1}{c|}{} & \multicolumn{4}{c|}{\textbf{Ground Truth Results}} &  & \multicolumn{4}{c|}{\textbf{Generated Results}} \\
			\multicolumn{1}{c|}{\textbf{Features}} & \textbf{10.0.0.100} & \textbf{10.0.0.27} & \textbf{10.0.0.22} & \textbf{10.0.99.143} &  & \textbf{10.0.0.100} & \textbf{10.0.0.27} & \textbf{10.0.0.22} & \textbf{10.0.99.143} \\ \cline{1-10}
			\multicolumn{1}{l|}{\textbf{A{\given}T}} & 0.244 & 0.238 & 0.153 & 0.333 &  & 0.260 & 0.288 & 0.196 & 0.539 \\
			\multicolumn{1}{l|}{\textbf{T{\given}S}} & 0.593 & 0.463 & 0.515 & 0.695 &  & 0.706 & 0.528 & 0.613 & 0.560 \\
			\multicolumn{1}{l|}{\textbf{T{\given}A}} & 0.330 & 0.339 & 0.695 & 0.246 &  & 0.567 & 0.536 & 0.824 & 0.359 \\
			\multicolumn{1}{l|}{\textbf{S{\given}T}} & 0.262 & 0.252 & 0.263 & 0.405 &  & 0.220 & 0.211 & 0.274 & 0.485 \\
			\multicolumn{1}{l|}{\textbf{S{\given}A}} & 0.800 & 0.752 & 0.831 & 0.711 &  & 0.280 & 0.340 & 0.572 & 0.367 \\
			\multicolumn{1}{l|}{\textbf{D{\given}S}} & 0.346 & 0.445 & 0.253 & 0.278 &  & 0.558 & 0.378 & 0.203 & 0.658 \\
			\multicolumn{1}{l|}{\textbf{A{\given}D}} & 0.080 & 0.222 & 0.070 & 0.288 &  & 0.140 & 0.109 & 0.074 & 0.181 \\
			\multicolumn{1}{l|}{\textbf{T{\given}D}} & 0.479 & 0.346 & 0.655 & 0.383 &  & 0.581 & 0.542 & 0.822 & 0.426 \\
			\multicolumn{1}{l|}{\textbf{D{\given}T}} & 0.287 & 0.234 & 0.152 & 0.379 &  & 0.382 & 0.276 & 0.176 & 0.614 \\
			\multicolumn{1}{l|}{\textbf{A{\given}S}} & 0.346 & 0.385 & 0.271 & 0.475 &  & 0.422 & 0.390 & 0.233 & 0.620 \\
			\multicolumn{1}{l|}{\textbf{S{\given}D}} & 0.822 & 0.779 & 0.856 & 0.785 &  & 0.309 & 0.346 & 0.567 & 0.379 \\
			\multicolumn{1}{l|}{\textbf{D{\given}A}} & 0.006 & 0.246 & 0.006 & 0.016 &  & 0.240 & 0.091 & 0.082 & 0.160 \\ \hline
			\multicolumn{1}{l|}{\textbf{S{\given}A,D}} & 0.799 & 0.747 & 0.829 & 0.705 &  & 0.278 & 0.327 & 0.562 & 0.342 \\
			\multicolumn{1}{l|}{\textbf{D{\given}S,T}} & 0.171 & 0.118 & 0.013 & 0.149 &  & 0.347 & 0.257 & 0.143 & 0.539 \\
			\multicolumn{1}{l|}{\textbf{S{\given}D,T}} & 0.107 & 0.025 & 0.101 & 0.024 &  & 0.158 & 0.190 & 0.246 & 0.335 \\
			\multicolumn{1}{l|}{\textbf{T{\given}A,D}} & 0.316 & 0.335 & 0.650 & 0.246 &  & 0.541 & 0.515 & 0.815 & 0.341 \\
			\multicolumn{1}{l|}{\textbf{A{\given}S,D}} & 0.069 & 0.206 & 0.056 & 0.245 &  & 0.124 & 0.399 & 0.066 & 0.165 \\
			\multicolumn{1}{l|}{\textbf{A{\given}S,T}} & 0.131 & 0.117 & 0.013 & 0.130 &  & 0.223 & 0.267 & 0.165 & 0.468 \\
			\multicolumn{1}{l|}{\textbf{A{\given}D,T}} & 0.038 & 0.018 & 0.001 & 0.004 &  & 0.102 & 0.083 & 0.061 & 0.126 \\
			\multicolumn{1}{l|}{\textbf{D{\given}A,S}} & 0.005 & 0.243 & 0.005 & 0.012 &  & 0.239 & 0.081 & 0.070 & 0.147 \\
			\multicolumn{1}{l|}{\textbf{T{\given}S,D}} & 0.393 & 0.340 & 0.587 & 0.348 &  & 0.496 & 0.399 & 0.573 & 0.396 \\
			\multicolumn{1}{l|}{\textbf{D{\given}A,T}} & 0.004 & 0.238 & 0.003 & 0.007 &  & 0.214 & 0.071 & 0.069 & 0.147 \\
			\multicolumn{1}{l|}{\textbf{S{\given}A,T}} & 0.211 & 0.178 & 0.100 & 0.228 &  & 0.151 & 0.186 & 0.253 & 0.324 \\
			\multicolumn{1}{l|}{\textbf{T{\given}A,S}} & 0.365 & 0.312 & 0.561 & 0.302 &  & 0.494 & 0.396 & 0.578 & 0.330 \\ \hline
			\multicolumn{1}{l|}{\textbf{A{\given}S,D,T}} & 0.041 & 0.172 & 0.028 & 0.195 &  & 0.097 & 0.076 & 0.051 & 0.110 \\
			\multicolumn{1}{l|}{\textbf{D{\given}A,S,T}} & 0.002 & 0.232 & 0.002 & 0.004 &  & 0.212 & 0.067 & 0.053 & 0.134 \\
			\multicolumn{1}{l|}{\textbf{S{\given}A,D,T}} & 0.209 & 0.167 & 0.498 & 0.222 &  & 0.467 & 0.182 & 0.240 & 0.299 \\
			\multicolumn{1}{l|}{\textbf{T{\given}A,S,D}} & 0.362 & 0.302 & 0.558 & 0.294 &  & 0.147 & 0.381 & 0.566 & 0.312
		\end{tabular}
	\end{adjustbox}
\end{table}

\begin{table}[!htbp]
	\caption{Normalized Joint Entropy Values for all Victim IPs: WGAN-GP Result}
	\label{tab:je}
	\centering
	\begin{adjustbox}{angle=90}
		\begin{tabular}{l|c|c|c|c|c|c|c|c|c|}
			\multicolumn{1}{c|}{} & \multicolumn{9}{c|}{\textbf{Victim Machine IP Address}} \\
			\multicolumn{1}{c|}{} & \multicolumn{4}{c|}{Ground Truth Results} &  & \multicolumn{4}{c|}{Generated Results} \\
			\multicolumn{1}{c|}{Features} & \textbf{10.0.0.100} & \textbf{10.0.0.27} & \textbf{10.0.0.22} & \textbf{10.0.99.143} &  & \textbf{10.0.0.100} & \textbf{10.0.0.27} & \textbf{10.0.0.22} & \textbf{10.0.99.143} \\ \hline
			\textbf{A,D} & 0.715 & 0.652 & 0.469 & 0.747 &  & 0.492 & 0.398 & 0.191 & 0.553 \\
			\textbf{A,S} & 0.704 & 0.683 & 0.674 & 0.749 &  & 0.462 & 0.531 & 0.456 & 0.652 \\
			\textbf{A,T} & 0.783 & 0.781 & 0.839 & 0.750 &  & 0.617 & 0.603 & 0.648 & 0.638 \\
			\textbf{D,T} & 0.811 & 0.807 & 0.858 & 0.767 &  & 0.682 & 0.592 & 0.608 & 0.672 \\
			\textbf{S,D} & 0.764 & 0.711 & 0.686 & 0.738 &  & 0.553 & 0.533 & 0.444 & 0.652 \\
			\textbf{S,T} & 0.816 & 0.801 & 0.842 & 0.773 &  & 0.672 & 0.642 & 0.665 & 0.593 \\ \hline
			\textbf{A,D,T} & 0.805 & 0.775 & 0.839 & 0.750 &  & 0.603 & 0.538 & 0.547 & 0.595 \\
			\textbf{A,S,D} & 0.735 & 0.683 & 0.674 & 0.749 &  & 0.508 & 0.478 & 0.389 & 0.579 \\
			\textbf{A,S,T} & 0.780 & 0.750 & 0.810 & 0.740 &  & 0.595 & 0.595 & 0.595 & 0.620 \\
			\textbf{S,D,T} & 0.806 & 0.775 & 0.810 & 0.748 &  & 0.646 & 0.595 & 0.581 & 0.647 \\ \hline
			\textbf{A,S,D,T} & 0.803 & 0.750 & 0.810 & 0.740 &  & 0.605 & 0.563 & 0.553 & 0.611
			\end{tabular}
	\end{adjustbox}
\end{table}

Several instances of feature dependency show good agreement between Fig. \ref{fig:alert_depend_1} and Table \ref{tab:ce}. For example, the drop in interesection score between A,S and A,S,T is low and the conditional entropy of the ground truth distribution T{\given}A,S is low. 

To further study specific feature-value relationships between the ground truth and generated data distributions conditional probability tables may be output for each feature permutation. In order to make these tables human-readable the following color schema is applied: cells which have probability 0 are highlighted in red; cells with probability 1 are highlighted in green. This two step process highlights both the sparsity of output probabilities as well as cases where the input results in a deterministic output. Specific examples of these tables for the ground truth distribution, WGAN-GP generated distribution, and WGAN-GPMI generated distribution will be covered in \ref{sec:gpmi_dep}

\subsection{WGAN-GPMI Feature Dependency Performance}
\label{sec:gpmi_dep}

All of the aforementioned plots and tables were created in duplicate in order to test the effect of Mutual Information maximization on the model's ability to capture feature dependencies.

First, the graph structure and highlighting in Fig. \ref{fig:alert_depend_1} was applied to the histogram intersection scores of the WGAN-GPMI model in Fig. \ref{fig:alert_depend_5}. Similar to the WGAN-GP model results, Appendix \ref{sec:depend_app} contains the results for the other three target IP addresses tested. Note that from this figure alone it is impossible to make a claim that feature dependencies are more fully captured by the WGAN-GPMI model. However by computing the conditional entropy in Table \ref{tab:ce2} it is apparent that the WGAN-GPMI model more closely imitates the entropy of the ground truth. In fact, several of the small valued m-tuples such as A{\given}T, T{\given}D, and D{\given}S,T all have identical conditional entropy values to the ground truth distribution.

\begin{figure}[!htbp]
	\centering
	\includegraphics[width=.75\textwidth]{GPMI_27}
	\caption{
		Target 10.0.0.27 Alert Dependency Graph: WGAN-GPMI Results
	}
	\label{fig:alert_depend_5}
\end{figure}

\begin{table}[!htbp]
	\caption{Weighted Normalized Conditional Entropy Values for all Target IPs: WGAN-GPMI Result}
	\label{tab:ce2}
	\centering
	\begin{adjustbox}{angle=90}
		\begin{tabular}{l|c|c|c|c|c|c|c|c|c|}
			\multicolumn{1}{c|}{} & \multicolumn{9}{c|}{\textbf{Victim Machine IP Address}} \\
			\multicolumn{1}{c|}{} & \multicolumn{4}{c|}{\textbf{Ground Truth Results}} &  & \multicolumn{4}{c|}{\textbf{Generated Results}} \\
			\multicolumn{1}{c|}{\textbf{Features}} & \textbf{10.0.0.100} & \textbf{10.0.0.27} & \textbf{10.0.0.22} & \textbf{10.0.99.143} &  & \textbf{10.0.0.100} & \textbf{10.0.0.27} & \textbf{10.0.0.22} & \textbf{10.0.99.143} \\ \cline{1-10}
			\multicolumn{1}{l|}{\textbf{A{\given}T}} & 0.244 & 0.238 & 0.153 & 0.333 &  & 0.244	& 0.238 &	0.153 &	0.334 \\
			\multicolumn{1}{l|}{\textbf{T{\given}S}} & 0.593 & 0.463 & 0.515 & 0.695 &  & 0.593	&	0.463	&	0.516	&	0.695 \\
			\multicolumn{1}{l|}{\textbf{T{\given}A}} & 0.330 & 0.339 & 0.695 & 0.246 &  & 0.330	&	0.339	&	0.695	&	0.246 \\
			\multicolumn{1}{l|}{\textbf{S{\given}T}} & 0.262 & 0.252 & 0.263 & 0.405 &  & 0.263	&	0.186	&	0.252	&	0.406 \\
			\multicolumn{1}{l|}{\textbf{S{\given}A}} & 0.800 & 0.752 & 0.831 & 0.711 &  & 0.229	&	0.239	&	0.526	&	0.222 \\
			\multicolumn{1}{l|}{\textbf{D{\given}S}} & 0.346 & 0.445 & 0.253 & 0.278 &  & 0.509	&	0.385	&	0.207	&	0.558 \\
			\multicolumn{1}{l|}{\textbf{A{\given}D}} & 0.080 & 0.222 & 0.070 & 0.288 &  & 0.149	&	0.026	&	0.007	&	0.097 \\
			\multicolumn{1}{l|}{\textbf{T{\given}D}} & 0.479 & 0.346 & 0.655 & 0.383 &  & 0.479	&	0.346	&	0.655	&	0.383 \\
			\multicolumn{1}{l|}{\textbf{D{\given}T}} & 0.287 & 0.234 & 0.152 & 0.379 &  & 0.287	&	0.234	&	0.152	&	0.379 \\
			\multicolumn{1}{l|}{\textbf{A{\given}S}} & 0.346 & 0.385 & 0.271 & 0.475 &  & 0.403	&	0.376	&	0.214	&	0.543 \\
			\multicolumn{1}{l|}{\textbf{S{\given}D}} & 0.822 & 0.779 & 0.856 & 0.785 &  & 0.436	&	0.260	&	0.474	&	0.301 \\
			\multicolumn{1}{l|}{\textbf{D{\given}A}} & 0.006 & 0.246 & 0.006 & 0.016 &  & 0.055	&	0.009	&	0.048	&	0.000 \\ \hline
			\multicolumn{1}{l|}{\textbf{S{\given}A,D}} & 0.799 & 0.747 & 0.829 & 0.705 &  & 0.228	&	0.226	&	0.474	&	0.222 \\
			\multicolumn{1}{l|}{\textbf{D{\given}S,T}} & 0.171 & 0.118 & 0.013 & 0.149 &  & 0.171	&	0.118	&	0.013	&	0.149 \\
			\multicolumn{1}{l|}{\textbf{S{\given}D,T}} & 0.107 & 0.025 & 0.101 & 0.024 &  & 0.107	&	0.025	&	0.101	&	0.024 \\
			\multicolumn{1}{l|}{\textbf{T{\given}A,D}} & 0.316 & 0.335 & 0.650 & 0.246 &  & 0.317	&	0.335	&	0.650	&	0.246 \\
			\multicolumn{1}{l|}{\textbf{A{\given}S,D}} & 0.069 & 0.206 & 0.056 & 0.245 &  & 0.018	&	0.003	&	0.007	&	0.055 \\
			\multicolumn{1}{l|}{\textbf{A{\given}S,T}} & 0.131 & 0.117 & 0.013 & 0.130 &  & 0.112	&	0.117	&	0.013	&	0.131 \\
			\multicolumn{1}{l|}{\textbf{A{\given}D,T}} & 0.038 & 0.018 & 0.001 & 0.004 &  & 0.038	&	0.018	&	0.001	&	0.004 \\
			\multicolumn{1}{l|}{\textbf{D{\given}A,S}} & 0.005 & 0.243 & 0.005 & 0.012 &  & 0.054	&	0.000	&	0.000	&	0.000 \\
			\multicolumn{1}{l|}{\textbf{T{\given}S,D}} & 0.393 & 0.340 & 0.587 & 0.348 &  & 0.176	&	0.144	&	0.334	&	0.170 \\
			\multicolumn{1}{l|}{\textbf{D{\given}A,T}} & 0.004 & 0.238 & 0.003 & 0.007 &  & 0.044	&	0.006	&	0.000	&	0.000 \\
			\multicolumn{1}{l|}{\textbf{S{\given}A,T}} & 0.211 & 0.178 & 0.100 & 0.228 &  & 0.055	&	0.012	&	0.100	&	0.019 \\
			\multicolumn{1}{l|}{\textbf{T{\given}A,S}} & 0.365 & 0.312 & 0.561 & 0.302 &  & 0.170	&	0.144	&	0.328	&	0.089 \\ \hline
			\multicolumn{1}{l|}{\textbf{A{\given}S,D,T}} & 0.041 & 0.172 & 0.028 & 0.195 &  & 0.005	&	0.003	&	0.000	&	0.001 \\
			\multicolumn{1}{l|}{\textbf{D{\given}A,S,T}} & 0.002 & 0.232 & 0.002 & 0.004 &  & 0.044	&	0.000	&	0.000	&	0.000 \\
			\multicolumn{1}{l|}{\textbf{T{\given}A,D,S}} & 0.209 & 0.167 & 0.498 & 0.222 &  & 0.157	&	0.144	&	0.328	&	0.089 \\
			\multicolumn{1}{l|}{\textbf{S{\given}A,T,D}} & 0.362 & 0.302 & 0.558 & 0.294 &  & 0.055	&	0.004	&	0.100	&	0.019
		\end{tabular}
	\end{adjustbox}
\end{table}

\begin{table}[!htbp]
	\caption{Normalized Joint Entropy Values for all Victim IPs: WGAN-GPMI Result}
	\label{tab:je2}
	\centering
	\begin{adjustbox}{angle=90}
		\begin{tabular}{l|c|c|c|c|c|c|c|c|c|}
			\multicolumn{1}{c|}{} & \multicolumn{9}{c|}{\textbf{Victim Machine IP Address}} \\
			\multicolumn{1}{c|}{} & \multicolumn{4}{c|}{\textbf{Ground Truth Results}} &  & \multicolumn{4}{c|}{\textbf{Generated Results}} \\
			\multicolumn{1}{c|}{\textbf{Features}} & \textbf{10.0.0.100} & \textbf{10.0.0.27} & \textbf{10.0.0.22} & \textbf{10.0.99.143} &  & \textbf{10.0.0.100} & \textbf{10.0.0.27} & \textbf{10.0.0.22} & \textbf{10.0.99.143} \\ \hline
			\textbf{A,D} & 0.715 & 0.652 & 0.469 & 0.747 &  & 0.532 & 0.457 & 0.192 & 0.453 \\
			\textbf{A,S} & 0.704 & 0.683 & 0.674 & 0.749 &  & 0.609 & 0.548 & 0.367 & 0.566 \\
			\textbf{A,T} & 0.783 & 0.781 & 0.839 & 0.750 &  & 0.693 & 0.616 & 0.665 & 0.554 \\
			\textbf{D,T} & 0.811 & 0.807 & 0.858 & 0.767 &  & 0.733 & 0.611 & 0.619 & 0.572 \\
			\textbf{S,D} & 0.764 & 0.711 & 0.686 & 0.738 &  & 0.657 & 0.552 & 0.353 & 0.567 \\
			\textbf{S,T} & 0.816 & 0.801 & 0.842 & 0.773 &  & 0.722 & 0.589 & 0.656 & 0.618 \\ \hline
			\textbf{A,D,T} & 0.805 & 0.775 & 0.839 & 0.750 &  & 0.651 & 0.555 & 0.577 & 0.521 \\
			\textbf{A,S,D} & 0.735 & 0.683 & 0.674 & 0.749 &  & 0.591 & 0.491 & 0.327 & 0.499 \\
			\textbf{A,S,T} & 0.780 & 0.750 & 0.810 & 0.740 &  & 0.678 & 0.579 & 0.597 & 0.564 \\
			\textbf{S,D,T} & 0.806 & 0.775 & 0.810 & 0.748 &  & 0.712 & 0.582 & 0.588 & 0.578 \\ \hline
			\textbf{A,S,D,T} & 0.803 & 0.750 & 0.810 & 0.740 &  & 0.680 & 0.557 & 0.568 & 0.547
		\end{tabular}
	\end{adjustbox}
\end{table}

Despite identical conditional entropy values existing between the ground truth and generated distribution it is important to note that this does not guarantee that the distributions are identical. Fundamentally, two different distributions can have the same entropy. Additionally, the conditional entropy calculation used is weighted by the probability that a given input conditioning value occurs. This allows inputs that occur frequently to have more influence over the conditional entropy value than inputs that occur rarely. Given a very small chance of an input occuring it's contribution to the conditional entropy calculation could become negligible. In order to better understand each model, the conditional probability tables showing inputs and their respective output probability were generated. Figure \ref{fig:make_this} shows subsections of the conditional probability table's from the ground truth, WGAN-GP generated, and WGAN-GPMI generated distributions. 

% TODO Add figure

The figure shows the conditional probability table for A{\given}D,T. All of the tables are formatted such that the input feature combination is given in the first column, the probability of that input occurring is given by the second column, the third column indicates the number of times that input occurred, and the remaining columns indicate the output values and their probability of occurring. This allows for identification of the influence each input combination would have on the conditional probability calculation.

Note that the ground truth distribution exhibits deterministic behavior for many of the input feature combinations. Capturing these cases of deterministic behavior is especially important for inputs which occur frequently. For example, the successfully learning the dependency between X and Y predicting the value of Z is important to model accuracy. The WGAN-GP generated distribution fails to do this, while the WGAN-GPMI distribution performs far better. 

Another interesting observation from these probability tables is that sometimes only a subset of the input conditioning values affects the output value. For example, if the given Destination Service value is (VALUE) then the output Alert Signature is (VALUE) regardless of the Time Bin value. Additionally, the table highlights that (VALUE) only occurs in Time Bin (VALUES).

Finally, several input combination instances that occur in the ground truth distribution never occur in the WGAN-GP generated distribution. These include (INPUTS). This is referred to as mode dropping and covered more in depth in Section \ref{sec:output}.

% TODO Output raw counts for conditional entropy tables
% Can some of the incorrect output signature ever occur from the inputs given
% Show ratio of incorrect modes over correct modes rather than number of combinations
% Show counts of those incorrect modes (how much probability mass is encompassed by the incorrect modes)

\section{Output Modes Captured}
\label{sec:output}
Finally, to assess output modes captured by each model, two values were collected; the number of values that existed in the ground truth that were not generated by the model and the number of values generated by the model that never occurred in the ground truth. Like all previous metrics, these values were collected for each unique m-tuple combination of features. Table \ref{tab:output_modes} shows the number of output modes missed by the generative model. The bottom two rows identify the number of unique output modes consisting of all 4 features for each target IP and the percentage of modes dropped.  Note that this table shows the direct benefit of mutual information maximization, as the number of output modes missed by the model decreases across the board for the WGAN-GPMI model. Some of the target IP addresses recover more modes than other when moving to the WGAN-GPMI model; 10.0.0.100, as well as 10.0.0.22,  halve the number of output modes dropped.


\begin{table}[!htbp]
	\centering
	\caption{Output Modes Dropped}
	\label{tab:output_modes}
	\begin{adjustbox}{angle=90}
		\begin{tabular}{ccccccccc}
			\multicolumn{1}{c|}{} & \multicolumn{4}{c|}{\textbf{Target IP Address (WGAN-GP)}} & \multicolumn{4}{c}{\textbf{Target IP Address (WGAN-GPMI)}} \\ \hline
			\multicolumn{1}{c|}{\textbf{M}} & \multicolumn{1}{l|}{\textbf{10.0.0.100}} & \multicolumn{1}{l|}{\textbf{10.0.0.27}} & \multicolumn{1}{l|}{\textbf{10.0.0.22}} & \multicolumn{1}{l|}{\textbf{10.0.99.143}} & \multicolumn{1}{l|}{\textbf{10.0.0.100}} & \multicolumn{1}{l|}{\textbf{10.0.0.27}} & \multicolumn{1}{l|}{\textbf{10.0.0.22}} & \multicolumn{1}{l}{\textbf{10.0.99.143}} \\ \hline
			\multicolumn{1}{c|}{\textbf{4}} & \multicolumn{1}{c|}{21} & \multicolumn{1}{c|}{15} & \multicolumn{1}{c|}{9} & \multicolumn{1}{c|}{10} & \multicolumn{1}{c|}{10} & \multicolumn{1}{c|}{14} & \multicolumn{1}{c|}{4} & 8 \\ \hline
			\multicolumn{1}{c|}{\multirow{4}{*}{\textbf{3}}} & \multicolumn{1}{c|}{14} & \multicolumn{1}{c|}{11} & \multicolumn{1}{c|}{3} & \multicolumn{1}{c|}{7} & \multicolumn{1}{c|}{9} & \multicolumn{1}{c|}{13} & \multicolumn{1}{c|}{3} & 8 \\
			\multicolumn{1}{c|}{} & \multicolumn{1}{c|}{20} & \multicolumn{1}{c|}{13} & \multicolumn{1}{c|}{8} & \multicolumn{1}{c|}{9} & \multicolumn{1}{c|}{5} & \multicolumn{1}{c|}{10} & \multicolumn{1}{c|}{3} & 7 \\
			\multicolumn{1}{c|}{} & \multicolumn{1}{c|}{18} & \multicolumn{1}{c|}{13} & \multicolumn{1}{c|}{5} & \multicolumn{1}{c|}{4} & \multicolumn{1}{c|}{5} & \multicolumn{1}{c|}{11} & \multicolumn{1}{c|}{2} & 5 \\
			\multicolumn{1}{c|}{} & \multicolumn{1}{c|}{16} & \multicolumn{1}{c|}{12} & \multicolumn{1}{c|}{7} & \multicolumn{1}{c|}{9} & \multicolumn{1}{c|}{6} & \multicolumn{1}{c|}{12} & \multicolumn{1}{c|}{3} & 4 \\ \hline
			\multicolumn{1}{c|}{\multirow{6}{*}{\textbf{2}}} & \multicolumn{1}{c|}{17} & \multicolumn{1}{c|}{11} & \multicolumn{1}{c|}{4} & \multicolumn{1}{c|}{4} & \multicolumn{1}{c|}{2} & \multicolumn{1}{c|}{7} & \multicolumn{1}{c|}{1} & 2 \\
			\multicolumn{1}{c|}{} & \multicolumn{1}{c|}{6} & \multicolumn{1}{c|}{2} & \multicolumn{1}{c|}{2} & \multicolumn{1}{c|}{3} & \multicolumn{1}{c|}{2} & \multicolumn{1}{c|}{6} & \multicolumn{1}{c|}{0} & 2 \\
			\multicolumn{1}{c|}{} & \multicolumn{1}{c|}{11} & \multicolumn{1}{c|}{9} & \multicolumn{1}{c|}{3} & \multicolumn{1}{c|}{2} & \multicolumn{1}{c|}{4} & \multicolumn{1}{c|}{10} & \multicolumn{1}{c|}{2} & 5 \\
			\multicolumn{1}{c|}{} & \multicolumn{1}{c|}{13} & \multicolumn{1}{c|}{9} & \multicolumn{1}{c|}{3} & \multicolumn{1}{c|}{7} & \multicolumn{1}{c|}{1} & \multicolumn{1}{c|}{2} & \multicolumn{1}{c|}{1} & 2 \\
			\multicolumn{1}{c|}{} & \multicolumn{1}{c|}{7} & \multicolumn{1}{c|}{6} & \multicolumn{1}{c|}{2} & \multicolumn{1}{c|}{4} & \multicolumn{1}{c|}{6} & \multicolumn{1}{c|}{11} & \multicolumn{1}{c|}{2} & 4 \\
			\multicolumn{1}{c|}{} & \multicolumn{1}{c|}{10} & \multicolumn{1}{c|}{7} & \multicolumn{1}{c|}{3} & \multicolumn{1}{c|}{3} & \multicolumn{1}{c|}{3} & \multicolumn{1}{c|}{8} & \multicolumn{1}{c|}{2} & 3 \\ \hline
			\multicolumn{1}{c|}{\multirow{4}{*}{\textbf{1}}} & \multicolumn{1}{c|}{5} & \multicolumn{1}{c|}{4} & \multicolumn{1}{c|}{2} & \multicolumn{1}{c|}{1} & \multicolumn{1}{c|}{1} & \multicolumn{1}{c|}{4} & \multicolumn{1}{c|}{2} & 1 \\
			\multicolumn{1}{c|}{} & \multicolumn{1}{c|}{1} & \multicolumn{1}{c|}{0} & \multicolumn{1}{c|}{0} & \multicolumn{1}{c|}{1} & \multicolumn{1}{c|}{2} & \multicolumn{1}{c|}{6} & \multicolumn{1}{c|}{1} & 3 \\
			\multicolumn{1}{c|}{} & \multicolumn{1}{c|}{0} & \multicolumn{1}{c|}{1} & \multicolumn{1}{c|}{0} & \multicolumn{1}{c|}{1} & \multicolumn{1}{c|}{0} & \multicolumn{1}{c|}{1} & \multicolumn{1}{c|}{0} & 0 \\
			\multicolumn{1}{c|}{} & \multicolumn{1}{c|}{10} & \multicolumn{1}{c|}{5} & \multicolumn{1}{c|}{3} & \multicolumn{1}{c|}{3} & \multicolumn{1}{c|}{1} & \multicolumn{1}{c|}{0} & \multicolumn{1}{c|}{0} & 1 \\ \hline
			\multicolumn{1}{l|}{\textbf{\# Unique Modes}} & \multicolumn{1}{c|}{32} & \multicolumn{1}{c|}{27} & \multicolumn{1}{c|}{22} & \multicolumn{1}{c|}{27} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l}{} \\
			\multicolumn{1}{l|}{\textbf{\% Modes Dropped}} & \multicolumn{1}{c|}{0.6563} & \multicolumn{1}{c|}{0.5556} & \multicolumn{1}{c|}{0.4091} & \multicolumn{1}{c|}{0.3704} & \multicolumn{1}{c|}{0.3125} & \multicolumn{1}{c|}{0.5185} & \multicolumn{1}{c|}{0.1818} & \multicolumn{1}{c}{0.2963}
		\end{tabular}
	\end{adjustbox}
\end{table}

Table \ref{tab:random_outputs} shows the number of noisy outputs by the generative model that did not occur in the ground truth. The bottom two rows of this table shows the number of unique modes and the ratio of noisy 4-tuple samples over the number of true combinations.  For target IP 10.0.99.143, the target IP tested with the lowest number of alerts, the WGAN-GPMI model appears to create less noisy outputs. Additionally 10.0.0.27 also sees a significant drop in the number of noisy outputs generated when using the WGAN-GPMI model. Interestingly, these are also the two IP addresses which did not experience a large decrease in the number of output modes dropped. One potential explanation for this would be that the missing output modes occur with such low probability that even with the mutual information constraint on the generator the model does not receive sufficient gradient feedback to learn to output these values. 

\begin{table}[!htbp]
	\centering
	\caption{Noisy Generator Output Counts}
	\label{tab:random_outputs}
	\begin{adjustbox}{angle=90}
		\begin{tabular}{c|c|c|c|c|c|c|c|c}
			\multicolumn{1}{c|}{} & \multicolumn{4}{c|}{\textbf{Target IP Address (WGAN-GP)}} & \multicolumn{4}{c}{\textbf{Target IP Address (WGAN-GPMI)}} \\ \hline

			\textbf{M} & \multicolumn{1}{l|}{\textbf{10.0.0.100}} & \multicolumn{1}{l|}{\textbf{10.0.0.27}} & \multicolumn{1}{l|}{\textbf{10.0.0.22}} & \multicolumn{1}{l|}{\textbf{10.0.99.143}} & \multicolumn{1}{l|}{\textbf{10.0.0.100}} & \multicolumn{1}{l|}{\textbf{10.0.0.27}} & \multicolumn{1}{l|}{\textbf{10.0.0.22}} & \multicolumn{1}{l}{\textbf{10.0.99.143}} \\
			\hline
			\textbf{4} & 168 & 235 & 76 & 321 & 213 & 97 & 107 & 98 \\
			\hline
			\multirow{4}{*}{\textbf{3}} & 131 & 112 & 46 & 192 & 103 & 60 & 63 & 50 \\
			& 119 & 97 & 36  & 240 & 83 & 40 & 34 & 40 \\
			& 49  & 23 & 6  & 187  & 117 & 57  & 52 & 57 \\
			& 54  & 46 & 17 & 174  & 84  & 57  & 68 & 40 \\
			\hline
			\multirow{6}{*}{\textbf{2}} & 70 & 23 & 29 & 95 & 31 & 23 & 13 & 20 \\
			& 22  & 0 & 0  & 60 & 11 & 12 & 12 & 4  \\
			& 12  & 1 & 1  & 68 & 39 & 24 & 12 & 21 \\
			& 10  & 9 & 3  & 71 & 20 & 14 & 11 & 8  \\
			& 20  & 5 & 1  & 94 & 14 & 16 & 26 & 3  \\
			& 19  & 2 & 1  & 58 & 23 & 20 & 22 & 10 \\
			\hline
			\multirow{4}{*}{\textbf{1}} & 0  & 0  & 0  & 5  & 0  & 0  & 0  & 0  \\
			& 2   & 0 & 0  & 24 & 0  & 0  & 0  & 0  \\
			& 11  & 0 & 0  & 17 & 0  & 0  & 0  & 0  \\
			& 0   & 0 & 0  & 30 & 0  & 0  & 0  & 1  \\
			\hline
			\multicolumn{1}{l|}{\textbf{\# Unique Modes}} & \multicolumn{1}{c|}{32} & \multicolumn{1}{c|}{27} & \multicolumn{1}{c|}{22} & \multicolumn{1}{c|}{27} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l}{} \\
			\multicolumn{1}{l|}{\textbf{Noise Ratio}} & 5.250 & 8.704 & 3.455 & 11.889 & 6.656 & 3.593 & 4.864 & 3.630
		\end{tabular}
	\end{adjustbox}
\end{table}

\section{Generality of Models}
\label{sec:cptc18}

One of the most powerful characteristics of Machine Learning models is their ability to adapt well to new datasets from the same domain. To ensure that the models presented here maintain generality we retrain each on the CPTC'18 dataset. This dataset continues to make use of Suricata alerts, however includes different feature values and is based off an attack on a completely new network architecture. The same features and preprocessing steps identified in Section \ref{sec:preproc} were applied to alerts from the four IP addresses that contained the most number of alerts. These IP addresses included 10.0.1.4, 10.0.1.5, 10.0.0.24, and 10.0.0.22. 

%TODO: Add table in here

After training each model the Histogram Intersection and Jensen Shannon Divergence were computed for each, as shown in Table \ref{tab:inter18} and Table \ref{tab:jsd18} respectively. Given the results, both models perform well at generating alerts which emulate the CPTC'18 data. Note that the prior observations regarding mutual information maximization increasing histogram intersection also hold true when applied to a new dataset. 


